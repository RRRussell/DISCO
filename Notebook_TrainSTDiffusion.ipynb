{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from utils import *\n",
    "from dataset import STDataset\n",
    "from baseline import RandomRegionBaseline, TissueSpecificRandomRegionBaseline\n",
    "from evaluate import Evaluator\n",
    "\n",
    "from parameter import create_args\n",
    "from models.common import get_linear_scheduler\n",
    "from models.vae_gaussian import GaussianVAE\n",
    "from models.vae_flow import FlowVAE\n",
    "from models.ddpm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeding all randomness with seed=2024\n"
     ]
    }
   ],
   "source": [
    "training_samples = generate_training_samples(num_samples_per_slice=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'striatum': 1}\n"
     ]
    }
   ],
   "source": [
    "tissue_distribution = count_dominant_tissue(training_samples)\n",
    "print(tissue_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAEiCAYAAAA21pHjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA0LklEQVR4nO3deVxN+f8H8NctdYu0jFRKKmlMoWUsyTI0IlsztpnGDKlsY5vIDLJlzzCSJWMZhBlf4WeZGUQixsggGvuYiHxRIboVKt3z+8Oj83VVtN+TXs/H4z4ecz73c855n1t5zeec8zlXJgiCACIiIpIkDXUXQERERMVjUBMREUkYg5qIiEjCGNREREQSxqAmIiKSMAY1ERGRhDGoiYiIJIxBTUREJGEMaiIiIgljUFOlmzVrFmQyWZXsq3PnzujcubO4HBsbC5lMhp07d1bJ/n19fWFtbV0l+yqrrKwsDBs2DGZmZpDJZBg/fry6SyqT6vBZl1dERARkMhlu3bql7lJIjRjUVCoF/3AUvHR0dGBubg5PT08sX74cmZmZFbKfe/fuYdasWUhISKiQ7VUkKddWEgsWLEBERARGjRqFLVu2YPDgwcX2tba2Fn/WGhoaMDQ0RIsWLTBixAj89ddfVVi19C1YsAB79ux5a7/OnTur/A0V95o1a1al10zVg4zP+qbSiIiIgJ+fH+bMmQMbGxvk5eUhJSUFsbGxiI6ORqNGjfDrr7/C0dFRXOfFixd48eIFdHR0Sryfs2fPonXr1ti4cSN8fX1LvF5ubi4AQFtbG8DLEbW7uzt27NiBAQMGlHg7Za0tLy8PSqUScrm8QvZVGdq2bYtatWrhxIkTb+1rbW0NIyMjTJw4EQCQmZmJq1evYseOHUhJScGECRMQGhpa2SUXSWqftZ6eHgYMGICIiIg39ouOjkZqaqq4fObMGSxfvhxTp06Fvb292O7o6IhmzZohLy8Pcrm8ys5KkfTUUncBVD316NEDrVq1EpeDgoJw5MgR9O7dG5988gmuXr0KXV1dAECtWrVQq1bl/qo9ffoUtWvXFgNaXbS0tNS6/5JIS0uDg4NDiftbWFhg0KBBKm3ff/89vvzySyxduhR2dnYYNWpURZf5VtXhsy5K165dVZZ1dHSwfPlydO3aVeWyTQFNTc0qqoykiqe+qcJ8/PHHmDFjBm7fvo2ff/5ZbC/qGnV0dDQ6dOgAQ0ND6OnpoWnTppg6dSqAl6Pg1q1bAwD8/PzEU4EFI5XOnTujefPmiI+Px0cffYTatWuL675+jbpAfn4+pk6dCjMzM9SpUweffPIJ7ty5o9LH2tq6yNH7q9t8W21FXTfNzs7GxIkTYWlpCblcjqZNm+KHH37A6yezZDIZxo4diz179qB58+aQy+Vo1qwZoqKiiv7AX5OWloahQ4fC1NQUOjo6cHJywqZNm8T3C67XJyUlYd++fWLtZbn+qauriy1btuC9997D/PnzVY6ltMe7Y8cOODg4QFdXF25ubrh48SIAYM2aNWjSpAl0dHTQuXPnQnW+/lnfunULMpkMP/zwA9auXQtbW1vI5XK0bt0aZ86cUVn3woUL8PX1RePGjaGjowMzMzP4+/vj0aNHKv0KfncTExPh6+sLQ0NDGBgYwM/PD0+fPlU5luzsbGzatEn8XEtzJqg4RV2jPnv2LDw9PWFsbAxdXV3Y2NjA399fZb1t27ahZcuWqFu3LvT19dGiRQssW7as0HGVZH8AcODAAXTs2BF16tRB3bp10atXL1y+fLncx0clwxE1VajBgwdj6tSpOHToEIYPH15kn8uXL6N3795wdHTEnDlzIJfLkZiYiD///BMAYG9vjzlz5mDmzJkYMWIEOnbsCABo166duI1Hjx6hR48e+OKLLzBo0CCYmpq+sa758+dDJpNh8uTJSEtLQ1hYGDw8PJCQkCCO/EuiJLW9ShAEfPLJJzh69CiGDh0KZ2dnHDx4EN999x3u3r2LpUuXqvQ/ceIEdu3ahdGjR6Nu3bpYvnw5+vfvj+TkZNSrV6/Yup49e4bOnTsjMTERY8eOhY2NDXbs2AFfX188efIEAQEBsLe3x5YtWzBhwgQ0bNhQPJ1dv379Eh//q/T09NC3b1+sX78eV65cQbNmzUp9vH/88Qd+/fVXjBkzBgAQEhKC3r17Y9KkSVi1ahVGjx6Nx48fY9GiRfD398eRI0feWtfWrVuRmZmJkSNHQiaTYdGiRejXrx9u3rwpjsKjo6Nx8+ZN+Pn5wczMDJcvX8batWtx+fJlnDp1qlCIff7557CxsUFISAjOnTuHn376CSYmJvj+++8BAFu2bMGwYcPQpk0bjBgxAgBga2tbps/1TdLS0tCtWzfUr18fU6ZMgaGhIW7duoVdu3aJfaKjozFw4EB06dJFrO/q1av4888/ERAQUOp9btmyBUOGDIGnpye+//57PH36FD/++CM6dOiA8+fPv/M39EmCQFQKGzduFAAIZ86cKbaPgYGB4OLiIi4HBwcLr/6qLV26VAAgPHjwoNhtnDlzRgAgbNy4sdB7nTp1EgAIq1evLvK9Tp06ictHjx4VAAgWFhaCQqEQ27dv3y4AEJYtWya2WVlZCUOGDHnrNt9U25AhQwQrKytxec+ePQIAYd68eSr9BgwYIMhkMiExMVFsAyBoa2urtP39998CAGHFihWF9vWqsLAwAYDw888/i225ubmCm5uboKenp3LsVlZWQq9evd64vZL2LfhZ7t27t0zHK5fLhaSkJLFtzZo1AgDBzMxMpeagoCABgErf1z/rpKQkAYBQr149IT09XWzfu3evAED47bffxLanT58WOpb//Oc/AgDh+PHjYlvB766/v79K3759+wr16tVTaatTp06Rvz9vs2PHDgGAcPTo0ULvFfy9FRz37t273/r3FxAQIOjr6wsvXrwots/rf5PF7S8zM1MwNDQUhg8frtIvJSVFMDAwKNROlYOnvqnC6enpvfHub0NDQwDA3r17oVQqy7QPuVwOPz+/Evf38fFB3bp1xeUBAwagQYMG2L9/f5n2X1L79++HpqYmvvnmG5X2iRMnQhAEHDhwQKXdw8NDZSTm6OgIfX193Lx58637MTMzw8CBA8U2LS0tfPPNN8jKysKxY8cq4GgK09PTAwDx513a4+3SpYvKiMzV1RUA0L9/f5WfV0H72z4HAPD29oaRkZG4XHDW49V1Xz2L8vz5czx8+BBt27YFAJw7d67QNr/++muV5Y4dO+LRo0dQKBRvraciFfzt/P7778jLyyu2T3Z2NqKjo8u9v+joaDx58gQDBw7Ew4cPxZempiZcXV1x9OjRcu+D3o5BTRUuKytL5R/Z13l7e6N9+/YYNmwYTE1N8cUXX2D79u2lCm0LC4tS3ThmZ2ensiyTydCkSZNKn596+/ZtmJubF/o8Cu7uvX37tkp7o0aNCm3DyMgIjx8/fut+7OzsoKGh+idd3H4qSlZWFgCIx1fe4zUwMAAAWFpaFtn+ts+hqG0WhPar66anpyMgIACmpqbQ1dVF/fr1YWNjAwDIyMgo0zarQqdOndC/f3/Mnj0bxsbG+PTTT7Fx40bk5OSIfUaPHo33338fPXr0QMOGDeHv71/i+xxe9++//wJ4ef9J/fr1VV6HDh1CWlpahRwXvRmvUVOF+u9//4uMjAw0adKk2D66uro4fvw4jh49in379iEqKgqRkZH4+OOPcejQoRLd5Vqa68olVdz0l/z8/Cq787a4/QgSnUV56dIlAHjjz/tNijve8nwOJVn3888/x8mTJ/Hdd9/B2dkZenp6UCqV6N69e5H/wyiVn0vBw3tOnTqF3377DQcPHoS/vz+WLFmCU6dOQU9PDyYmJkhISMDBgwdx4MABHDhwABs3boSPj494c+GbftdfVfBZbNmyBWZmZoX6V/ZsDnqJI2qqUFu2bAEAeHp6vrGfhoYGunTpgtDQUFy5cgXz58/HkSNHxFNpFT1ntGBkUEAQBCQmJqqcdjUyMsKTJ08Krfv6KLA0tVlZWeHevXuFLgVcu3ZNfL8iWFlZ4d9//y0UMhW9n1dlZWVh9+7dsLS0FEfMVXW85fH48WPExMRgypQpmD17Nvr27YuuXbuicePG5dpuVc5zbtu2LebPn4+zZ8/il19+weXLl7Ft2zbxfW1tbXh5eWHVqlW4ceMGRo4cic2bNyMxMRHA/84IvP77/vrvesFlGBMTE3h4eBR6FTXDgioeg5oqzJEjRzB37lzY2Njgq6++KrZfenp6oTZnZ2cAEE/h1alTB0Dhf0jKavPmzSrhsXPnTty/fx89evQQ22xtbXHq1CnxoSnAy2uBr0/jKk1tPXv2RH5+PlauXKnSvnTpUshkMpX9l0fPnj2RkpKCyMhIse3FixdYsWIF9PT00KlTpwrZT4Fnz55h8ODBSE9Px7Rp08SQqqrjLY+C0fHro+GwsLBybbdOnToV9vtanMePHxeq+/W/ndenmGloaIgPICroUxDAx48fF/sVTC97laenJ/T19bFgwYIir4k/ePCgHEdDJcXzFlQmBw4cwLVr1/DixQukpqbiyJEjiI6OhpWVFX799dc3PoVszpw5OH78OHr16gUrKyukpaVh1apVaNiwITp06ADg5T8khoaGWL16NerWrYs6derA1dVVvI5YWu+99x46dOgAPz8/pKamIiwsDE2aNFGZQjZs2DDs3LkT3bt3x+eff44bN27g559/LjTNpjS1eXl5wd3dHdOmTcOtW7fg5OSEQ4cOYe/evRg/fnyFTeEZMWIE1qxZA19fX8THx8Pa2ho7d+7En3/+ibCwsDfeM/A2d+/eFefFZ2Vl4cqVK+KTySZOnIiRI0eKfavqeMtDX18fH330ERYtWoS8vDxYWFjg0KFDSEpKKtd2W7ZsicOHDyM0NBTm5uawsbERb4KrKJs2bcKqVavQt29f2NraIjMzE+vWrYO+vj569uwJ4OXvcXp6Oj7++GM0bNgQt2/fxooVK+Ds7Cye+ejWrRsaNWqEoUOH4rvvvoOmpiY2bNiA+vXrIzk5Wdyfvr4+fvzxRwwePBgffvghvvjiC7HPvn370L59+0L/U0aVQG33m1O1VDB9o+Clra0tmJmZCV27dhWWLVumMqWmwOtTQWJiYoRPP/1UMDc3F7S1tQVzc3Nh4MCBwvXr11XW27t3r+Dg4CDUqlVLZTpUp06dhGbNmhVZX3HTs/7zn/8IQUFBgomJiaCrqyv06tVLuH37dqH1lyxZIlhYWAhyuVxo3769cPbs2ULbfFNtr08ZEoSXU1wmTJggmJubC1paWoKdnZ2wePFiQalUqvQDIIwZM6ZQTcVNG3tdamqq4OfnJxgbGwva2tpCixYtipxCVtrpWQU/a5lMJujr6wvNmjUThg8fLvz1119FrlOe4y2YYrV48WKV9oKf444dO8S24qZnvb5uwb6Cg4PF5f/+979C3759BUNDQ8HAwED47LPPhHv37hXqV/C7+/pUwtenMQmCIFy7dk346KOPBF1dXQFAiadqlWZ61rlz54SBAwcKjRo1EuRyuWBiYiL07t1bOHv2rLjOzp07hW7dugkmJiaCtra20KhRI2HkyJHC/fv3VbYdHx8vuLq6in1CQ0OLPC5BePn5e3p6CgYGBoKOjo5ga2sr+Pr6quyXKg+f9U1ERCRhvEZNREQkYQxqIiIiCWNQExERSRiDmoiISMIY1ERERBLGoCYiIpKwGvfAE6VSiXv37qFu3bpV+sg/IiKiAoIgIDMzE+bm5oW+TOd1NS6o7927V+ibeYiIiNThzp07aNiw4Rv71LigLniU4p07d6Cvr6/maoiIqCZSKBSwtLQs0eN9a1xQF5zu1tfXZ1ATEZFaleQSLG8mIyIikjC1BvXx48fh5eUFc3NzyGQy7Nmz563rxMbG4sMPP4RcLkeTJk0QERFR6XUSERGpi1qDOjs7G05OTggPDy9R/6SkJPTq1Qvu7u5ISEjA+PHjMWzYMBw8eLCSKyUiIlIPtV6j7tGjR6m+SH716tWwsbHBkiVLAAD29vY4ceIEli5dCk9Pz8oqk4iISG2q1TXquLg4eHh4qLR5enoiLi6u2HVycnKgUChUXkRERNVFtbrrOyUlBaampiptpqamUCgUePbsGXR1dQutExISgtmzZ1daTQvPP6y0bRMRkbRMcTGu8n1WqxF1WQQFBSEjI0N83blzR90lERERlVi1GlGbmZkhNTVVpS01NRX6+vpFjqYBQC6XQy6XV0V5REREFa5ajajd3NwQExOj0hYdHQ03Nzc1VURERFS51BrUWVlZSEhIQEJCAoCX068SEhKQnJwM4OVpax8fH7H/119/jZs3b2LSpEm4du0aVq1ahe3bt2PChAnqKJ+IiKjSqTWoz549CxcXF7i4uAAAAgMD4eLigpkzZwIA7t+/L4Y2ANjY2GDfvn2Ijo6Gk5MTlixZgp9++olTs4iI6J0lEwRBUHcRVUmhUMDAwAAZGRkV8qxv3vVNRFRzVNRd36XJomp1jZqIiKimYVATERFJGIOaiIhIwhjUREREEsagJiIikjAGNRERkYQxqImIiCSMQU1ERCRhDGoiIiIJY1ATERFJGIOaiIhIwhjUREREEsagJiIikjAGNRERkYQxqImIiCSMQU1ERCRhDGoiIiIJY1ATERFJGIOaiIhIwhjUREREEsagJiIikjC1B3V4eDisra2ho6MDV1dXnD59+o39w8LC0LRpU+jq6sLS0hITJkzA8+fPq6haIiKiqqXWoI6MjERgYCCCg4Nx7tw5ODk5wdPTE2lpaUX237p1K6ZMmYLg4GBcvXoV69evR2RkJKZOnVrFlRMREVUNtQZ1aGgohg8fDj8/Pzg4OGD16tWoXbs2NmzYUGT/kydPon379vjyyy9hbW2Nbt26YeDAgW8dhRMREVVXagvq3NxcxMfHw8PD43/FaGjAw8MDcXFxRa7Trl07xMfHi8F88+ZN7N+/Hz179ix2Pzk5OVAoFCovIiKi6qKWunb88OFD5Ofnw9TUVKXd1NQU165dK3KdL7/8Eg8fPkSHDh0gCAJevHiBr7/++o2nvkNCQjB79uwKrZ2IiKiqqP1mstKIjY3FggULsGrVKpw7dw67du3Cvn37MHfu3GLXCQoKQkZGhvi6c+dOFVZMRERUPmobURsbG0NTUxOpqakq7ampqTAzMytynRkzZmDw4MEYNmwYAKBFixbIzs7GiBEjMG3aNGhoFP7/DrlcDrlcXvEHQEREVAXUNqLW1tZGy5YtERMTI7YplUrExMTAzc2tyHWePn1aKIw1NTUBAIIgVF6xREREaqK2ETUABAYGYsiQIWjVqhXatGmDsLAwZGdnw8/PDwDg4+MDCwsLhISEAAC8vLwQGhoKFxcXuLq6IjExETNmzICXl5cY2ERERO8StQa1t7c3Hjx4gJkzZyIlJQXOzs6IiooSbzBLTk5WGUFPnz4dMpkM06dPx927d1G/fn14eXlh/vz56joEIiKiSiUTatg5Y4VCAQMDA2RkZEBfX7/c21t4/mEFVEVERNXBFBfjCtlOabKoWt31TUREVNMwqImIiCSMQU1ERCRhDGoiIiIJY1ATERFJGIOaiIhIwhjUREREEsagJiIikjAGNRERkYQxqImIiCSMQU1ERCRhDGoiIiIJY1ATERFJGIOaiIhIwhjUREREEsagJiIikjAGNRERkYQxqImIiCSsTEHduHFjPHr0qFD7kydP0Lhx43IXRURERC+VKahv3bqF/Pz8Qu05OTm4e/duuYsiIiKil2qVpvOvv/4q/vfBgwdhYGAgLufn5yMmJgbW1talKiA8PByLFy9GSkoKnJycsGLFCrRp06bY/k+ePMG0adOwa9cupKenw8rKCmFhYejZs2ep9ktERFQdlCqo+/TpAwCQyWQYMmSIyntaWlqwtrbGkiVLSry9yMhIBAYGYvXq1XB1dUVYWBg8PT3xzz//wMTEpFD/3NxcdO3aFSYmJti5cycsLCxw+/ZtGBoaluYwiIiIqo1SBbVSqQQA2NjY4MyZMzA2Ni7XzkNDQzF8+HD4+fkBAFavXo19+/Zhw4YNmDJlSqH+GzZsQHp6Ok6ePAktLS0AKPUInoiIqDop0zXqpKSkcod0bm4u4uPj4eHh8b9iNDTg4eGBuLi4Itf59ddf4ebmhjFjxsDU1BTNmzfHggULirxeTkRE9C4o1Yj6VTExMYiJiUFaWpo40i6wYcOGt67/8OFD5Ofnw9TUVKXd1NQU165dK3Kdmzdv4siRI/jqq6+wf/9+JCYmYvTo0cjLy0NwcHCR6+Tk5CAnJ0dcVigUb62NiIhIKsoU1LNnz8acOXPQqlUrNGjQADKZrKLrKpJSqYSJiQnWrl0LTU1NtGzZEnfv3sXixYuLDeqQkBDMnj27SuojIiKqaGUK6tWrVyMiIgKDBw8u846NjY2hqamJ1NRUlfbU1FSYmZkVuU6DBg2gpaUFTU1Nsc3e3h4pKSnIzc2FtrZ2oXWCgoIQGBgoLisUClhaWpa5biIioqpUpmvUubm5aNeuXbl2rK2tjZYtWyImJkZsUyqViImJgZubW5HrtG/fHomJiSqn2q9fv44GDRoUGdIAIJfLoa+vr/IiIiKqLsoU1MOGDcPWrVvLvfPAwECsW7cOmzZtwtWrVzFq1ChkZ2eLd4H7+PggKChI7D9q1Cikp6cjICAA169fx759+7BgwQKMGTOm3LUQERFJUZlOfT9//hxr167F4cOH4ejoKE6VKhAaGlqi7Xh7e+PBgweYOXMmUlJS4OzsjKioKPEGs+TkZGho/O//JSwtLXHw4EFMmDABjo6OsLCwQEBAACZPnlyWwyAiIpI8mSAIQmlXcnd3L36DMhmOHDlSrqIqk0KhgIGBATIyMirkNPjC8w8roCoiIqoOpriUb2pygdJkUZlG1EePHi1TYURERFQ6/JpLIiIiCSvTiNrd3f2Nc6elfOqbiIioOilTUDs7O6ss5+XlISEhAZcuXSr0ZR1ERERUdmUK6qVLlxbZPmvWLGRlZZWrICIiIvqfCr1GPWjQoBI955uIiIhKpkKDOi4uDjo6OhW5SSIiohqtTKe++/Xrp7IsCALu37+Ps2fPYsaMGRVSGBEREZUxqA0MDFSWNTQ00LRpU8yZMwfdunWrkMKIiIiojEG9cePGiq6DiIiIilCmoC4QHx+Pq1evAgCaNWsGFxeXCimKiIiIXipTUKelpeGLL75AbGwsDA0NAQBPnjyBu7s7tm3bhvr161dkjURERDVWme76HjduHDIzM3H58mWkp6cjPT0dly5dgkKhwDfffFPRNRIREdVYZRpRR0VF4fDhw7C3txfbHBwcEB4ezpvJiIiIKlCZRtRKpbLQd1ADgJaWFpRKZbmLIiIiopfKFNQff/wxAgICcO/ePbHt7t27mDBhArp06VJhxREREdV0ZQrqlStXQqFQwNraGra2trC1tYWNjQ0UCgVWrFhR0TUSERHVWGW6Rm1paYlz587h8OHDuHbtGgDA3t4eHh4eFVocERFRTVeqEfWRI0fg4OAAhUIBmUyGrl27Yty4cRg3bhxat26NZs2a4Y8//qisWomIiGqcUgV1WFgYhg8fDn19/ULvGRgYYOTIkQgNDa2w4oiIiGq6UgX133//je7duxf7frdu3RAfH1/uooiIiOilUgV1ampqkdOyCtSqVQsPHjwodRHh4eGwtraGjo4OXF1dcfr06RKtt23bNshkMvTp06fU+yQiIqoOShXUFhYWuHTpUrHvX7hwAQ0aNChVAZGRkQgMDERwcDDOnTsHJycneHp6Ii0t7Y3r3bp1C99++y06duxYqv0RERFVJ6UK6p49e2LGjBl4/vx5ofeePXuG4OBg9O7du1QFhIaGYvjw4fDz84ODgwNWr16N2rVrY8OGDcWuk5+fj6+++gqzZ89G48aNS7U/IiKi6qRUQT19+nSkp6fj/fffx6JFi7B3717s3bsX33//PZo2bYr09HRMmzatxNvLzc1FfHy8yrQuDQ0NeHh4IC4urtj15syZAxMTEwwdOrQ05RMREVU7pZpHbWpqipMnT2LUqFEICgqCIAgAAJlMBk9PT4SHh8PU1LTE23v48CHy8/MLrWNqairOz37diRMnsH79eiQkJJRoHzk5OcjJyRGXFQpFiesjIiJSt1I/8MTKygr79+/H48ePkZiYCEEQYGdnByMjo8qoT0VmZiYGDx6MdevWwdjYuETrhISEYPbs2ZVcGRERUeUo05PJAMDIyAitW7cu186NjY2hqamJ1NRUlfbU1FSYmZkV6n/jxg3cunULXl5eYlvBl4DUqlUL//zzD2xtbVXWCQoKQmBgoLisUChgaWlZrrqJiIiqSpmDuiJoa2ujZcuWiImJEadYKZVKxMTEYOzYsYX6f/DBB7h48aJK2/Tp05GZmYlly5YVGcByuRxyubxS6iciIqpsag1qAAgMDMSQIUPQqlUrtGnTBmFhYcjOzoafnx8AwMfHBxYWFggJCYGOjg6aN2+usr6hoSEAFGonIiJ6F6g9qL29vfHgwQPMnDkTKSkpcHZ2RlRUlHiDWXJyMjQ0yvQlX0RERNWeTCi4dbuGUCgUMDAwQEZGRpHPLC+thecfVkBVRERUHUxxKdmNzG9TmiziUJWIiEjCGNREREQSxqAmIiKSMAY1ERGRhDGoiYiIJIxBTUREJGEMaiIiIgljUBMREUkYg5qIiEjCGNREREQSxqAmIiKSMAY1ERGRhDGoiYiIJIxBTUREJGEMaiIiIgljUBMREUkYg5qIiEjCGNREREQSxqAmIiKSMAY1ERGRhDGoiYiIJEwSQR0eHg5ra2vo6OjA1dUVp0+fLrbvunXr0LFjRxgZGcHIyAgeHh5v7E9ERFSdqT2oIyMjERgYiODgYJw7dw5OTk7w9PREWlpakf1jY2MxcOBAHD16FHFxcbC0tES3bt1w9+7dKq6ciIio8skEQRDUWYCrqytat26NlStXAgCUSiUsLS0xbtw4TJky5a3r5+fnw8jICCtXroSPj89b+ysUChgYGCAjIwP6+vrlrn/h+Yfl3gYREVUPU1yMK2Q7pckitY6oc3NzER8fDw8PD7FNQ0MDHh4eiIuLK9E2nj59iry8PLz33nuVVSYREZHa1FLnzh8+fIj8/HyYmpqqtJuamuLatWsl2sbkyZNhbm6uEvavysnJQU5OjrisUCjKXjAREVEVU/s16vJYuHAhtm3bht27d0NHR6fIPiEhITAwMBBflpaWVVwlERFR2ak1qI2NjaGpqYnU1FSV9tTUVJiZmb1x3R9++AELFy7EoUOH4OjoWGy/oKAgZGRkiK87d+5USO1ERERVQa1Bra2tjZYtWyImJkZsUyqViImJgZubW7HrLVq0CHPnzkVUVBRatWr1xn3I5XLo6+urvIiIiKoLtV6jBoDAwEAMGTIErVq1Qps2bRAWFobs7Gz4+fkBAHx8fGBhYYGQkBAAwPfff4+ZM2di69atsLa2RkpKCgBAT08Penp6ajsOIiKiyqD2oPb29saDBw8wc+ZMpKSkwNnZGVFRUeINZsnJydDQ+N/A/8cff0Rubi4GDBigsp3g4GDMmjWrKksnIiKqdGqfR13VOI+aiIjKqsbNoyYiIqI3Y1ATERFJGIOaiIhIwhjUREREEsagJiIikjAGNRERkYQxqImIiCSMQU1ERCRhDGoiIiIJY1ATERFJGIOaiIhIwhjUREREEsagJiIikjAGNRERkYQxqImIiCSMQU1ERCRhDGoiIiIJY1ATERFJGIOaiIhIwhjUREREEsagJiIikjBJBHV4eDisra2ho6MDV1dXnD59+o39d+zYgQ8++AA6Ojpo0aIF9u/fX0WVEhERVS21B3VkZCQCAwMRHByMc+fOwcnJCZ6enkhLSyuy/8mTJzFw4EAMHToU58+fR58+fdCnTx9cunSpiisnIiKqfDJBEAR1FuDq6orWrVtj5cqVAAClUglLS0uMGzcOU6ZMKdTf29sb2dnZ+P3338W2tm3bwtnZGatXr37r/hQKBQwMDJCRkQF9ff1y17/w/MNyb4OIiKqHKS7GFbKd0mRRrQrZYxnl5uYiPj4eQUFBYpuGhgY8PDwQFxdX5DpxcXEIDAxUafP09MSePXuK7J+Tk4OcnBxxOSMjA8DLD6kiPM/KrJDtEBGR9CkU2hW0nZcZVJKxslqD+uHDh8jPz4epqalKu6mpKa5du1bkOikpKUX2T0lJKbJ/SEgIZs+eXajd0tKyjFUTEVFNVThNyiczMxMGBgZv7KPWoK4KQUFBKiNwpVKJ9PR01KtXDzKZTI2VEVVfCoUClpaWuHPnToVcQiKqaQRBQGZmJszNzd/aV61BbWxsDE1NTaSmpqq0p6amwszMrMh1zMzMStVfLpdDLpertBkaGpa9aCIS6evrM6iJyuhtI+kCar3rW1tbGy1btkRMTIzYplQqERMTAzc3tyLXcXNzU+kPANHR0cX2JyIiqs7Ufuo7MDAQQ4YMQatWrdCmTRuEhYUhOzsbfn5+AAAfHx9YWFggJCQEABAQEIBOnTphyZIl6NWrF7Zt24azZ89i7dq16jwMIiKiSqH2oPb29saDBw8wc+ZMpKSkwNnZGVFRUeINY8nJydDQ+N/Av127dti6dSumT5+OqVOnws7ODnv27EHz5s3VdQhENY5cLkdwcHChy0pEVPHUPo+aiIiIiqf2J5MRERFR8RjUREREEsagJiIikjAGNRERkYQxqImIiCSMQU1ERCRhDGoiKhJnbhJJA4OaiMRQTkpKQnx8PPLy8vilNUQSwaAmIshkMuzatQtubm7w8vKCo6Mj9uzZg+zsbHWXRlTjMaiJajhBEHDv3j3Mnz8f06dPR1RUFBwcHDB58mRs27YNWVlZ6i6RqEZjUBPVUAWnuwVBgJGRETp27Ag/Pz84Ojri//7v/+Dm5oZFixYhMjKSYU2kRmr/Ug4iUg+ZTIZ9+/YhIiICycnJ0NHRwYsXL8T3IyIiMGTIECxduhTPnz+Hr68v6tSpo8aKiWomjqiJaqhTp07h008/hZGRETQ1NXHhwgUsWrQIjx8/Fvts2rQJ77//PjZt2qQS4kRUdfjtWUQ10D///INdu3ZBLpcjMDAQwMvvhj9x4gQ++eQTjBs3DgYGBmL/e/fuwdzcXF3lEtVoHFET1TA3btzAyJEjsXz5cpXvkw4NDUWHDh2wZ88ehIeHq4ysGdJE6sOgJqoBXj1x1qhRI7i7u0NHRwd79+5VmYIVGhoKd3d3rF+/HuvXr+dDT4gkgEFNVAPIZDIcO3YM27dvh5aWFqZNm4ZRo0bh0aNHmDx5MhQKhdh38eLF+OKLL9C/f38+9IRIAniNmqgGePr0KcaPH4/t27dj/fr16N+/P/Ly8rBo0SL8/vvv+PDDDxESEgJ9fX11l0pEr+H0LKJ3mCAIkMlkqF27NgICAqClpYXx48dDqVTis88+w6RJkwAAUVFRGDduHFauXIm6deuquWoiehWDmugdlpGRAUNDQwBAs2bNMHbsWOTn5yMwMBAymQwDBgzApEmT8PTpU5w5cwbZ2dkMaiKJ4alvonfU+fPn4ePjg+XLl8Pd3V1sv3LlCkJCQhATE4P169ejR48eyMvLg0KhQL169dRYMREVhTeTEVVzSqUSAJCfny+25ebmok6dOrC0tMR3332HP/74Q3zPwcEBgwYNwqNHj9CnTx/s3r0bWlpaDGkiiWJQE1VzGhoauHnzJiIiIgAA27Ztg4ODA+zs7DB16lQ0btwYY8eOxfHjx8V1rK2t0aNHD3z77bdo0aKFmionopLgNWqid8CqVauwefNm/PXXX9i8eTNWrFgBmUyGDh06AACWL1+O0aNHIzQ0FO3atcMvv/wCuVyOSZMmqTyBjIikh9eoid4RvXv3xv79+zF48GBERESozIE+deoU1qxZg02bNqFZs2a4c+cOjh07BicnJzVWTEQlwaAmquZyc3NRq1Yt9O/fH1lZWbh9+zbGjx+PL7/8UrzjGwCys7Nx8uRJPH78GK6urrCyslJf0URUYgxqondEXl4etLS0MHLkSMTExCAwMBBfffWVeGpboVDwgSZE1RCDmqgaKniQyfXr15GamgpdXV28//77YhCPHDkSR44cwfjx4/H5559jxYoV2LZtG65cuQJNTU0+GpSoGmFQE1UzBSG9e/dujBs3DkZGRrh9+zYGDRqEL7/8UryBbMyYMThw4ADq1q2L1NRU7NmzB23btlVz9URUWrzrm6iayM/PF0fD0dHRGDp0KObNm4fRo0dj06ZNGD16NNLS0pCXlwd3d3eEh4dj9+7dePr0Kdq2bQtbW1t1HwIRlQFH1EQS9+OPP2LUqFHiclZWFsaPHw8TExMsWLAAt2/fRpcuXdC4cWMkJyejcePGCAoKQseOHdVYNRFVFD7whEjCrly5gnXr1uHGjRtim5aWFgYPHgwfHx88fvwYn376KTp16oRDhw5h6tSpOH78OObNm6fyNDIiqr4Y1EQSZmdnh9jYWNja2uL06dMAALlcDhcXF3zwwQfYv38/ateujfnz5wMAateuDTs7O2hpaaFx48bqLJ2IKgiDmkiilEoltLS0oK+vj9TUVPj5+cHNzQ0AxLu7MzMzoVAo8PDhQwAvv4jD29sbv/zyCywsLNRWOxFVHF6jJpKogru7jx07hqysLDx//hyzZs1CgwYNcOjQIQAvv0c6ICAApqam0NTUxJkzZxAXF8fndxO9QziiJpKogpB2d3eHhoYGunfvjoULFyI5ORldu3YFAHTv3h3z5s2Dq6sr7O3tcfr0aYY00TuGI2oiibp16xaOHz+O5ORkTJ8+HcDLp48dOnQIEydOhIWFBWJiYgC8HH0D4INMiN5BHFETSYQgCGLgpqamwtbWFsOGDUNOTo7YR0tLC926dcOSJUuQlpaG1q1bA3gZ0AxponcTg5pIjZRKJQDg+fPnYtgmJSXBxMQE27dvR+3atXH58mUoFApxnYKwnj17NmQyGZKTk9VVPhFVAQY1kRppaGjgzp07GD58OFJSUrB37164uLggMTER/fv3x08//YTff/8d8+bNw4sXL8T1tLS04OXlhaNHj6JRo0ZqPAIiqmx8hCiRmp05cwa3bt1C3759cf78eWzYsAF2dnYQBAEDBgxAfn4+Bg0aBA0NDcybNw+1ar38s9XS0oKWlpaaqyeiysagJlKTgulX/fr1w+XLlxEcHAwXFxdxrnRBH29vbwCAn58fsrKyEBYWJoY1Eb37eOqbSM3Onz+PZ8+eYe7cuTA2NsaECRNw4cIFyGQy8QYzb29vrFmzBtu3b0d6erq6SyaiKsSgJlKDV7+q8rPPPoOGhgamTZsGX19fZGZmYsaMGbhw4QI0NDQgk8lw/vx5DBo0CDdu3ICJiYm6yyeiKsR51ERqsm/fPnz22WdYtmwZPD09xZvC9uzZg1WrVkFHRwcTJ05EbGwswsPDcfXqVdSrV0/NVRNRVWNQE6nB8+fP4ePjAzs7O8yfPx9Pnz7F3bt3sWfPHjg5OeHixYs4fvw4zp49C7lcjm3btqFNmzbqLpuI1IB3pBCpgSAISEpKgpmZGdLT0xEcHIyLFy/i+vXr0NTUREBAAJYvX460tDSYm5vzCzaIajBeoyZSA11dXYwbNw4//fQTbGxscPfuXfj7++PevXvo168fDhw4gIYNG6J169YMaaIajiNqIjXx8fFBq1atcPfuXXTt2lV8Sll+fj4sLCzw4sULaGpqqrlKIlI3XqMmkohr165hy5YtCA8Px4kTJ9C8eXN1l0REEsARNZEExMfHY8mSJUhISMCxY8cY0kQk4oiaSAKePXuGs2fPwtraGpaWluouh4gkhEFNREQkYbzrm4iISMIY1ERERBLGoCYiIpIwBjUREZGEMaiJiIgkjEFNREQkYQxqIiIiCWNQE1Vjvr6+6NOnj7rLIKJKxKAmkiiZTPbG16xZs7Bs2TJERESou9RCbt269db6pVg3kRTxyWREEpWSkiL+d2RkJGbOnIl//vlHbNPT04Oenp46Snur/Px8PHjwQFz+4YcfEBUVhcOHD4ttBgYG0NXVVUd5RNUKR9REEmVmZia+DAwMIJPJVNr09PQKnfreuXMnWrRoAV1dXdSrVw8eHh7Izs4GAMTGxqJNmzaoU6cODA0N0b59e9y+fRtA0afQx48fj86dO4vLSqUSISEhsLGxga6uLpycnLBz584ia9fU1CxUa61atWBmZobnz5/D3Nwcly9fVlknLCwMVlZWUCqViI2NhUwmw759++Do6AgdHR20bdsWly5dUlnnxIkT6NixI3R1dWFpaYlvvvlGPF6idwWDmugdcf/+fQwcOBD+/v64evUqYmNj0a9fPwiCgBcvXqBPnz7o1KkTLly4gLi4OIwYMQIymazE2w8JCcHmzZuxevVqXL58GRMmTMCgQYNw7NixUtVpbW0NDw8PbNy4UaV948aN8PX1hYbG//5Z+u6777BkyRKcOXMG9evXh5eXF/Ly8gAAN27cQPfu3dG/f39cuHABkZGROHHiBMaOHVuqeoikjl9zSfSOuH//Pl68eIF+/frBysoKANCiRQsAQHp6OjIyMtC7d2/Y2toCAOzt7Uu87ZycHCxYsACHDx+Gm5sbAKBx48Y4ceIE1qxZg06dOpWq1mHDhuHrr79GaGgo5HI5zp07h4sXL2Lv3r0q/YKDg9G1a1cAwKZNm9CwYUPs3r0bn3/+OUJCQvDVV19h/PjxAAA7OzssX74cnTp1wo8//ggdHZ1S1UQkVRxRE70jnJyc0KVLF7Ro0QKfffYZ1q1bh8ePHwMA3nvvPfj6+sLT0xNeXl5YtmwZ7t+/X+JtJyYm4unTp+jatat4bVxPTw+bN2/GjRs3Sl1rnz59oKmpid27dwMAIiIi4O7uDmtra5V+Bf9TUHAMTZs2xdWrVwEAf//9NyIiIlTq8fT0hFKpRFJSUqlrIpIqBjXRO0JTUxPR0dE4cOAAHBwcsGLFCjRt2lQMrY0bNyIuLg7t2rVDZGQk3n//fZw6dQoAoKGhgdfvKy04xQwAWVlZAIB9+/YhISFBfF25cqXY69Rvoq2tDR8fH2zcuBG5ubnYunUr/P39S7WNrKwsjBw5UqWev//+G//++6941oDoXcBT30TvEJlMhvbt26N9+/aYOXMmrKyssHv3bgQGBgIAXFxc4OLigqCgILi5uWHr1q1o27Yt6tevX+hGrYSEBGhpaQEAHBwcIJfLkZycXOrT3MUZNmwYmjdvjlWrVomn7F936tQpNGrUCADw+PFjXL9+XTxl/+GHH+LKlSto0qRJhdRDJFUMaqJ3xF9//YWYmBh069YNJiYm+Ouvv/DgwQPY29sjKSkJa9euxSeffAJzc3P8888/+Pfff+Hj4wMA+Pjjj7F48WJs3rwZbm5u+Pnnn3Hp0iW4uLgAAOrWrYtvv/0WEyZMgFKpRIcOHZCRkYE///wT+vr6GDJkSKnrtbe3R9u2bTF58mT4+/sXOVVrzpw5qFevHkxNTTFt2jQYGxuLd6dPnjwZbdu2xdixYzFs2DDUqVMHV65cQXR0NFauXFn2D5JIYhjURO8IfX19HD9+HGFhYVAoFLCyssKSJUvQo0cPpKam4tq1a9i0aRMePXqEBg0aYMyYMRg5ciQAwNPTEzNmzMCkSZPw/Plz+Pv7w8fHBxcvXhS3P3fuXNSvXx8hISG4efMmDA0N8eGHH2Lq1Kllrnno0KE4efJksae9Fy5ciICAAPz7779wdnbGb7/9Bm1tbQCAo6Mjjh07hmnTpqFjx44QBAG2trbw9vYucz1EUsQHnhCR2sydOxc7duzAhQsXVNpjY2Ph7u6Ox48fw9DQUD3FEUkEbyYjoiqXlZWFS5cuYeXKlRg3bpy6yyGSNAY1EVW5sWPHomXLlujcuXOp7/Ymqml46puIiEjCOKImIiKSMAY1ERGRhDGoiYiIJIxBTUREJGEMaiIiIgljUBMREUkYg5qIiEjCGNREREQSxqAmIiKSsP8HMPKzoViCoSIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_tissue_distribution(tissue_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_training_samples = filter_training_sample_by_tissue(training_samples, tissue_name=\"striatum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filter_training_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tissue_index = {\n",
    "    'striatum': 0,\n",
    "    'cortical layer VI': 1,\n",
    "    'cortical layer V': 2,\n",
    "    'corpus callosum': 3,\n",
    "    'cortical layer II/III': 4,\n",
    "    'pia mater': 5\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = STDataset(training_samples)\n",
    "# dataset = STDataset(filter_training_samples)\n",
    "# Define a DataLoader to handle batching\n",
    "# dataloader = DataLoader(dataset, batch_size=10, shuffle=True, num_workers=4)\n",
    "dataloader = DataLoader(dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 20\n",
    "n_T = 400 # 500\n",
    "device = \"cuda:0\"\n",
    "lrate = 1e-4\n",
    "ws_test = [0.0, 0.5, 2.0] # strength of generative guidance\n",
    "\n",
    "ddpm = DDPM(nn_model=STModel(n_positions=2, n_features=374, n_tissues=6, device=device), betas=(1e-4, 0.02), n_T=n_T, device=device, drop_prob=0.1)\n",
    "ddpm.to(device)\n",
    "optim = torch.optim.Adam(ddpm.parameters(), lr=lrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9488: 100%|██████████| 1/1 [00:00<00:00, 30.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position loss: 0.8601347208023071 expression loss: 1.0886945724487305\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.2297: 100%|██████████| 1/1 [00:00<00:00, 112.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position loss: 1.1502419710159302 expression loss: 1.0795050859451294\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9181: 100%|██████████| 1/1 [00:00<00:00, 119.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position loss: 0.8401119709014893 expression loss: 1.0779387950897217\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.0822: 100%|██████████| 1/1 [00:00<00:00, 119.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position loss: 1.027677297592163 expression loss: 1.0545517206192017\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9981: 100%|██████████| 1/1 [00:00<00:00, 122.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position loss: 0.9367026090621948 expression loss: 1.0614473819732666\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.1742: 100%|██████████| 1/1 [00:00<00:00, 124.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position loss: 1.0964142084121704 expression loss: 1.0777499675750732\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.0143: 100%|██████████| 1/1 [00:00<00:00, 123.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position loss: 0.9674491882324219 expression loss: 1.0468145608901978\n",
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7526: 100%|██████████| 1/1 [00:00<00:00, 124.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position loss: 0.6766349673271179 expression loss: 1.0759891271591187\n",
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9879: 100%|██████████| 1/1 [00:00<00:00, 121.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position loss: 0.9126201272010803 expression loss: 1.0752793550491333\n",
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.0923: 100%|██████████| 1/1 [00:00<00:00, 122.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position loss: 1.0135756731033325 expression loss: 1.0786950588226318\n",
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.1527: 100%|██████████| 1/1 [00:00<00:00, 122.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position loss: 1.0797865390777588 expression loss: 1.0729179382324219\n",
      "Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.8677: 100%|██████████| 1/1 [00:00<00:00, 123.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position loss: 0.7913554310798645 expression loss: 1.0763403177261353\n",
      "Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.0533: 100%|██████████| 1/1 [00:00<00:00, 125.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position loss: 0.9977559447288513 expression loss: 1.0555394887924194\n",
      "Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.2651: 100%|██████████| 1/1 [00:00<00:00, 122.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position loss: 1.1872620582580566 expression loss: 1.0778120756149292\n",
      "Epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.1310: 100%|██████████| 1/1 [00:00<00:00, 123.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position loss: 1.0626707077026367 expression loss: 1.0683677196502686\n",
      "Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.1611: 100%|██████████| 1/1 [00:00<00:00, 122.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position loss: 1.057089924812317 expression loss: 1.1039754152297974\n",
      "Epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.0006: 100%|██████████| 1/1 [00:00<00:00, 121.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position loss: 0.922959566116333 expression loss: 1.077613115310669\n",
      "Epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9637: 100%|██████████| 1/1 [00:00<00:00, 123.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position loss: 0.8995869159698486 expression loss: 1.0641580820083618\n",
      "Epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.8863:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position loss: 0.8278281688690186 expression loss: 1.0584982633590698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.8863: 100%|██████████| 1/1 [00:00<00:00, 125.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9286: 100%|██████████| 1/1 [00:00<00:00, 120.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position loss: 0.8761769533157349 expression loss: 1.0524095296859741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for ep in range(n_epoch):\n",
    "    print(f'Epoch {ep}')\n",
    "    ddpm.train()\n",
    "\n",
    "    # Linear learning rate decay\n",
    "    optim.param_groups[0]['lr'] = lrate * (1 - ep / n_epoch)\n",
    "\n",
    "    pbar = tqdm(dataloader)\n",
    "    loss_ema = None  # Exponential moving average of the loss\n",
    "    for batch in pbar:\n",
    "        optim.zero_grad()\n",
    "\n",
    "        # Extract positions, expressions, and tissue types from the batch\n",
    "        positions = batch['positions'].to(device)\n",
    "        expressions = batch['expressions'].to(device)\n",
    "        # Assuming 'dominant_tissue' is coded as integers for indexing into embeddings\n",
    "        tissue_types = batch['metadata']['dominant_tissue']  # This line might need adjustment based on actual encoding\n",
    "\n",
    "        # Concatenate positions and expressions for the model input\n",
    "        x = torch.cat((positions, expressions), dim=-1)\n",
    "\n",
    "        # Generate a dummy tensor for context (tissue types), adjust as needed\n",
    "        # For example, you might need to convert tissue types from strings to integers if not already\n",
    "        c = torch.tensor([tissue_index[tissue] for tissue in tissue_types]).to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        loss, noise, predicted_noise = ddpm(x, c)\n",
    "        loss.backward()\n",
    "\n",
    "        # Update loss EMA\n",
    "        if loss_ema is None:\n",
    "            loss_ema = loss.item()\n",
    "        else:\n",
    "            loss_ema = 0.95 * loss_ema + 0.05 * loss.item()\n",
    "\n",
    "        # Update progress bar\n",
    "        pbar.set_description(f\"Loss: {loss_ema:.4f}\")\n",
    "\n",
    "        optim.step()\n",
    "\n",
    "    # Optionally, add validation or image saving code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 1.9263,  0.2715,  0.8240,  ...,  0.4464, -1.3039, -1.7271],\n",
       "          [-0.8197, -0.0710,  0.7984,  ...,  0.5889, -1.6013,  0.1976],\n",
       "          [-0.5162, -0.5854,  0.5279,  ...,  0.5317, -0.3844,  1.8515],\n",
       "          ...,\n",
       "          [-0.8661, -1.0417,  0.5678,  ...,  0.1218,  1.1905,  0.4543],\n",
       "          [ 1.5326,  0.6228, -0.3223,  ...,  0.9833, -0.4401,  0.9108],\n",
       "          [-0.4402,  1.1277,  1.0124,  ...,  0.7819,  0.8948, -0.7658]]],\n",
       "        device='cuda:0'),\n",
       " tensor([[[ 7.9622e-02,  4.0176e-02,  1.3904e-01,  ...,  6.0368e-02,\n",
       "           -1.7750e-01,  8.6198e-02],\n",
       "          [ 1.8619e-02, -8.2049e-03,  2.1265e-01,  ...,  1.6216e-01,\n",
       "           -2.4983e-01,  1.9754e-01],\n",
       "          [ 1.3943e-01, -1.8676e-02,  1.7447e-01,  ...,  1.6658e-01,\n",
       "           -1.8316e-01,  2.3128e-01],\n",
       "          ...,\n",
       "          [ 1.1125e-01, -2.0203e-01,  2.2600e-01,  ...,  3.8332e-01,\n",
       "           -2.3087e-01,  2.2376e-01],\n",
       "          [ 2.8054e-02, -5.0093e-05,  8.3798e-02,  ...,  4.2396e-02,\n",
       "           -1.2804e-01,  1.6952e-02],\n",
       "          [-1.2821e-01,  2.2884e-02,  2.5036e-01,  ...,  6.5021e-02,\n",
       "           -2.7179e-01,  1.0952e-01]]], device='cuda:0',\n",
       "        grad_fn=<PermuteBackward0>))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise, predicted_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionaries to store metrics for both baselines\n",
    "metrics = {\n",
    "    'Diffusion': {\n",
    "        'mse': [],\n",
    "        'f1': [],\n",
    "        'cosine_sim': [],\n",
    "        'chamfer_dist': [],\n",
    "        'emd': []\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeding all randomness with seed=2024\n",
      "Donor_id: MsBrainAgingSpatialDonor_1\n",
      "Slice_id: 0\n",
      "Donor_id: MsBrainAgingSpatialDonor_2\n",
      "Slice_id: 0\n",
      "Slice_id: 1\n",
      "Donor_id: MsBrainAgingSpatialDonor_3\n",
      "Slice_id: 0\n",
      "Slice_id: 1\n",
      "Donor_id: MsBrainAgingSpatialDonor_4\n",
      "Slice_id: 0\n",
      "Slice_id: 1\n",
      "Slice_id: 2\n",
      "Donor_id: MsBrainAgingSpatialDonor_5\n",
      "Slice_id: 0\n",
      "Slice_id: 1\n",
      "Slice_id: 2\n",
      "Donor_id: MsBrainAgingSpatialDonor_6\n",
      "Slice_id: 0\n",
      "Slice_id: 1\n",
      "Slice_id: 2\n",
      "Donor_id: MsBrainAgingSpatialDonor_7\n",
      "Slice_id: 0\n",
      "Slice_id: 1\n",
      "Slice_id: 2\n",
      "Donor_id: MsBrainAgingSpatialDonor_8\n",
      "Slice_id: 0\n",
      "Slice_id: 1\n",
      "Slice_id: 2\n",
      "Donor_id: MsBrainAgingSpatialDonor_9\n",
      "Slice_id: 0\n",
      "Slice_id: 1\n",
      "Slice_id: 2\n",
      "Donor_id: MsBrainAgingSpatialDonor_10\n",
      "Slice_id: 0\n",
      "Slice_id: 1\n",
      "Slice_id: 2\n",
      "Donor_id: MsBrainAgingSpatialDonor_11\n",
      "Slice_id: 0\n",
      "Slice_id: 1\n",
      "Slice_id: 2\n",
      "Donor_id: MsBrainAgingSpatialDonor_12\n",
      "Slice_id: 0\n",
      "Slice_id: 1\n"
     ]
    }
   ],
   "source": [
    "all_test_items = load_test_data(num_holes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Area 1:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Step 1/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 2/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 3/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 4/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 5/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 6/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 7/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 8/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 9/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 10/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 11/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 12/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 13/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 14/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 15/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 16/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 17/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 18/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 19/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 20/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 21/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 22/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 23/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 24/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 25/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 26/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 27/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 28/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 29/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 30/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 31/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 32/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 33/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 34/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 35/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 36/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 37/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 38/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 39/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 40/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 41/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 42/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 43/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 44/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 45/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 46/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 47/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 48/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 49/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 50/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 51/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 52/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 53/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 54/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 55/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 56/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 57/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 58/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 59/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 60/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 61/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 62/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 63/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 64/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 65/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 66/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 67/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 68/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 69/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 70/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 71/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 72/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 73/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 74/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 75/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 76/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 77/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 78/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 79/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 80/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 81/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 82/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 83/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 84/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 85/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 86/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 87/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 88/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 89/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 90/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 91/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 92/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 93/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 94/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 95/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 96/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 97/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 98/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 99/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 100/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 101/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 102/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 103/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 104/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 105/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 106/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 107/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 108/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 109/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 110/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 111/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 112/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 113/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 114/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 115/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 116/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 117/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 118/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 119/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 120/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 121/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 122/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 123/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 124/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 125/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 126/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 127/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 128/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 129/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 130/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 131/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 132/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 133/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 134/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 135/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 136/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 137/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 138/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 139/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 140/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 141/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 142/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 143/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 144/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 145/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 146/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 147/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 148/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 149/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 150/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 151/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 152/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 153/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 154/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 155/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 156/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 157/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 158/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 159/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 160/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 161/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 162/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 163/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 164/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 165/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 166/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 167/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 168/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 169/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 170/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 171/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 172/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 173/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 174/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 175/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 176/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 177/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 178/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 179/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 180/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 181/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 182/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 183/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 184/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 185/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 186/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 187/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 188/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 189/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 190/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 191/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 192/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 193/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 194/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 195/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 196/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 197/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 198/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 199/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 200/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 201/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 202/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 203/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 204/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 205/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 206/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 207/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 208/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 209/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 210/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 211/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 212/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 213/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 214/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 215/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 216/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 217/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 218/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 219/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 220/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 221/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 222/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 223/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 224/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 225/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 226/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 227/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 228/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 229/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 230/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 231/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 232/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 233/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 234/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 235/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 236/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 237/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 238/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 239/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 240/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 241/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 242/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 243/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 244/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 245/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 246/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 247/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 248/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 249/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 250/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 251/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 252/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 253/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 254/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 255/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 256/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 257/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 258/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 259/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 260/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 261/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 262/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 263/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 264/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 265/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 266/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 267/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 268/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 269/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 270/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 271/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 272/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 273/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 274/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 275/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 276/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 277/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 278/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 279/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 280/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 281/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 282/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 283/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 284/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 285/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 286/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 287/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 288/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 289/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 290/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 291/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 292/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 293/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 294/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 295/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 296/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 297/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 298/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 299/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 300/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 301/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 302/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 303/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 304/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 305/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 306/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 307/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 308/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 309/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 310/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 311/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 312/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 313/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 314/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 315/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 316/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 317/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 318/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 319/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 320/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 321/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 322/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 323/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 324/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 325/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 326/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 327/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 328/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 329/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 330/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 331/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 332/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 333/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 334/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 335/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 336/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 337/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 338/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 339/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 340/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 341/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 342/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 343/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 344/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 345/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 346/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 347/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 348/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 349/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 350/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 351/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 352/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 353/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 354/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 355/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 356/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 357/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 358/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 359/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 360/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 361/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 362/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 363/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 364/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 365/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 366/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 367/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 368/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 369/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 370/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 371/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 372/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 373/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 374/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 375/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 376/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 377/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 378/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 379/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 380/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 381/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 382/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 383/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 384/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 385/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 386/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 387/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 388/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 389/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 390/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 391/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 392/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 393/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 394/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 395/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 396/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 397/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 398/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 399/400, Sample Shape: torch.Size([1, 50, 376])\n",
      "Step 400/400, Sample Shape: torch.Size([1, 50, 376])\n"
     ]
    }
   ],
   "source": [
    "for i, test_item in enumerate(all_test_items):\n",
    "    print(f\"Test Area {i+1}:\")\n",
    "    print(f\"  Dominant Tissue: {test_item.test_area.dominant_tissue}\")\n",
    "    print(f\"  Number of cells in ground truth: {len(test_item.ground_truth.hole_cells)}\")\n",
    "    \n",
    "    test_tissue_index = tissue_index[test_item.test_area.dominant_tissue]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        x = ddpm.sample_single(test_tissue_index)\n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Area 1:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 2:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 3:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 4:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 5:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 6:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 7:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 8:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 9:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 10:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 11:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 12:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 13:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 14:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 15:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 16:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 17:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 18:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 19:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 20:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 21:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 22:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 23:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 24:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 25:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 26:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 27:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 28:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 29:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 30:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 31:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 32:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 33:\n",
      "  Dominant Tissue: cortical layer II/III\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 34:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 35:\n",
      "  Dominant Tissue: cortical layer II/III\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 36:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 37:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 38:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 39:\n",
      "  Dominant Tissue: cortical layer II/III\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 40:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 41:\n",
      "  Dominant Tissue: cortical layer II/III\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 42:\n",
      "  Dominant Tissue: cortical layer II/III\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 43:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 44:\n",
      "  Dominant Tissue: cortical layer II/III\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 45:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 46:\n",
      "  Dominant Tissue: cortical layer II/III\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 47:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 48:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 49:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 50:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 51:\n",
      "  Dominant Tissue: cortical layer II/III\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 52:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 53:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 54:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 55:\n",
      "  Dominant Tissue: cortical layer II/III\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 56:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 57:\n",
      "  Dominant Tissue: cortical layer II/III\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 58:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 59:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 60:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 61:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 62:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 63:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 64:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 65:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 66:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 67:\n",
      "  Dominant Tissue: cortical layer II/III\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 68:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 69:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 70:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 71:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 72:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 73:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 74:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 75:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 76:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 77:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 78:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 79:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 80:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 81:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 82:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 83:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 84:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 85:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 86:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 87:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 88:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 89:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 90:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 91:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 92:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 93:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 94:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 95:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 96:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 97:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 98:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 99:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 100:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 101:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 102:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 103:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 104:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 105:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 106:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 107:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 108:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 109:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 110:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 111:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 112:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 113:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 114:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 115:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 116:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 117:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 118:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 119:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 120:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 121:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 122:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 123:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 124:\n",
      "  Dominant Tissue: cortical layer II/III\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 125:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 126:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 127:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 128:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 129:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 130:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 131:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 132:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 133:\n",
      "  Dominant Tissue: cortical layer II/III\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 134:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 135:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 136:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 137:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 138:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 139:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 140:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 141:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 142:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 143:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 144:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 145:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 146:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 147:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 148:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 149:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 150:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 151:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 152:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 153:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 154:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 155:\n",
      "  Dominant Tissue: pia mater\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 156:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 157:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 158:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 159:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 160:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 161:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 162:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 163:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 164:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 165:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 166:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 167:\n",
      "  Dominant Tissue: cortical layer II/III\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 168:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 169:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 170:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 171:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 172:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 173:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 174:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 175:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 176:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 177:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 178:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 179:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 180:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 181:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 182:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 183:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 184:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 185:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 186:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 187:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 188:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 189:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 190:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 191:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 192:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 193:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 194:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 195:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 196:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 197:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 198:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 199:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 200:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 201:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 202:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 203:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 204:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 205:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 206:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 207:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 208:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 209:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 210:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 211:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 212:\n",
      "  Dominant Tissue: cortical layer II/III\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 213:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 214:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 215:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 216:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 217:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 218:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 219:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 220:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 221:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 222:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 223:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 224:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 225:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 226:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 227:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 228:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 229:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 230:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 231:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 232:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 233:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 234:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 235:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 236:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 237:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 238:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 239:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 240:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 241:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 242:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 243:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 244:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 245:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 246:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 247:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 248:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 249:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 250:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 251:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 252:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 253:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 254:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 255:\n",
      "  Dominant Tissue: cortical layer II/III\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 256:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 257:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 258:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 259:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 260:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 261:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 262:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 263:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 264:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 265:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 266:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 267:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 268:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 269:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 270:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 271:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 272:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 273:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 274:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 275:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 276:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 277:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 278:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 279:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 280:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 281:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 282:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 283:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 284:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 285:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 286:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 287:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 288:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 289:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 290:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 291:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 292:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 293:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 294:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 295:\n",
      "  Dominant Tissue: cortical layer II/III\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 296:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 297:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 298:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 299:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 300:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 301:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 302:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 303:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 304:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 305:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 306:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 307:\n",
      "  Dominant Tissue: cortical layer II/III\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 308:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 309:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 310:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n"
     ]
    }
   ],
   "source": [
    "for i, test_item in enumerate(all_test_items):\n",
    "    print(f\"Test Area {i+1}:\")\n",
    "    print(f\"  Dominant Tissue: {test_item.test_area.dominant_tissue}\")\n",
    "    print(f\"  Number of cells in ground truth: {len(test_item.ground_truth.hole_cells)}\")\n",
    "    \n",
    "    test_tissue_index = tissue_index[test_item.test_area.dominant_tissue]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        x = ddpm.sample_single(test_tissue_index)\n",
    "\n",
    "    true_coords = test_item.ground_truth.hole_cells[['center_x', 'center_y']].values\n",
    "    true_gene_expressions = test_item.ground_truth.gene_expression\n",
    "\n",
    "    pred_coords, pred_gene_expressions = x[:,:2].cpu().numpy(), x[:,2:].cpu().numpy()\n",
    "\n",
    "    mse_r, f1_r, cosine_sim_r = Evaluator.evaluate_expression(true_coords, true_gene_expressions, pred_coords, pred_gene_expressions)\n",
    "    chamfer_dist_r = Evaluator.chamfer_distance(true_coords, pred_coords)\n",
    "    emd_r = Evaluator.calculate_emd(true_coords, pred_coords)\n",
    "    \n",
    "    # Collect results for RandomRegionBaseline\n",
    "    metrics['Diffusion']['mse'].append(mse_r)\n",
    "    metrics['Diffusion']['f1'].append(f1_r)\n",
    "    metrics['Diffusion']['cosine_sim'].append(cosine_sim_r)\n",
    "    metrics['Diffusion']['chamfer_dist'].append(chamfer_dist_r)\n",
    "    metrics['Diffusion']['emd'].append(emd_r)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Diffusion:\n",
      "  Mse: Mean = 133.7422, Std = 3.6864\n",
      "  F1: Mean = 0.4806, Std = 0.0253\n",
      "  Cosine_sim: Mean = 0.0005, Std = 0.0158\n",
      "  Chamfer_dist: Mean = 9334.3917, Std = 3861.8560\n",
      "  Emd: Mean = 4729.6487, Std = 1930.9434\n"
     ]
    }
   ],
   "source": [
    "for method in metrics:\n",
    "    print(f\"Results for {method}:\")\n",
    "    for metric in metrics[method]:\n",
    "        mean_value = np.mean(metrics[method][metric])\n",
    "        std_value = np.std(metrics[method][metric])\n",
    "        print(f\"  {metric.capitalize()}: Mean = {mean_value:.4f}, Std = {std_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 18.89246   ,  -7.8724885 ],\n",
       "       [  3.269108  ,   2.5687957 ],\n",
       "       [  0.62583494,  -8.384888  ],\n",
       "       [ -5.341048  ,  14.861167  ],\n",
       "       [ -1.92481   ,  -7.6973968 ],\n",
       "       [ -0.07300501,  10.406919  ],\n",
       "       [  9.232348  ,  -3.1947715 ],\n",
       "       [ 12.027211  ,  -3.1064465 ],\n",
       "       [ 11.359305  ,  -7.851377  ],\n",
       "       [ 10.968288  , -14.891005  ],\n",
       "       [  8.740383  ,  -1.2143338 ],\n",
       "       [-21.773565  ,   0.974317  ],\n",
       "       [-11.692947  ,   4.405701  ],\n",
       "       [ 15.088957  , -20.625978  ],\n",
       "       [-15.567964  ,  16.817184  ],\n",
       "       [ -4.137413  , -13.010883  ],\n",
       "       [ 23.590746  ,  -8.371495  ],\n",
       "       [ 14.34189   ,  -4.850592  ],\n",
       "       [ -4.5174174 ,  -8.73691   ],\n",
       "       [-14.390679  ,  10.583577  ],\n",
       "       [ -1.1503048 ,  -6.626029  ],\n",
       "       [  2.5693953 , -10.742705  ],\n",
       "       [  3.4566798 ,  -1.7911329 ],\n",
       "       [ 13.862366  , -10.5903015 ],\n",
       "       [ -8.057493  ,  16.51877   ],\n",
       "       [-12.454074  ,   7.467543  ],\n",
       "       [ 13.068814  ,  -0.037971  ],\n",
       "       [  6.2850876 ,   3.7190948 ],\n",
       "       [ -7.8756976 ,  -1.2625024 ],\n",
       "       [ -2.6312227 ,  -8.151148  ],\n",
       "       [ -6.9456024 , -10.535583  ],\n",
       "       [-11.946466  ,  -0.25155   ],\n",
       "       [ 10.546717  , -10.503632  ],\n",
       "       [  3.912754  , -15.199132  ],\n",
       "       [ 10.9594965 ,   1.8882866 ],\n",
       "       [-14.825741  ,  10.190001  ],\n",
       "       [  6.6590605 ,  10.330982  ],\n",
       "       [ 13.277969  ,  10.706252  ],\n",
       "       [  2.9772022 ,  -0.40158918],\n",
       "       [ 10.984077  ,  -9.349778  ],\n",
       "       [ -0.9457438 ,   0.9312054 ],\n",
       "       [ -2.9798872 ,   2.3665872 ],\n",
       "       [ 13.595331  , -10.691067  ],\n",
       "       [-16.04628   ,   1.4326026 ],\n",
       "       [  9.946022  ,  -2.6402152 ],\n",
       "       [ -4.8018813 , -10.891648  ],\n",
       "       [ -0.9457333 ,   1.6039296 ],\n",
       "       [-12.804911  ,   2.6175601 ],\n",
       "       [ 13.55534   ,  -6.731904  ],\n",
       "       [ -3.2341177 ,  -9.559399  ]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  1574.13703701, -10953.75719899],\n",
       "        [  1490.38553421, -11037.68719697],\n",
       "        [  1565.30803722, -10973.15919852],\n",
       "        [  1627.71053572, -10946.89019915],\n",
       "        [  1570.92153709, -11030.54769714],\n",
       "        [  1593.10303655, -10955.61019894],\n",
       "        [  1540.72853781, -11030.05719715],\n",
       "        [  1523.17953824, -10953.53919899],\n",
       "        [  1645.2050353 , -10943.51119924],\n",
       "        [  1647.22153525, -11078.017196  ],\n",
       "        [  1624.76753579, -11012.50819758],\n",
       "        [  1558.98603737, -10967.43669866],\n",
       "        [  1554.95303747, -10934.79119945],\n",
       "        [  1664.77053483, -10973.70419851],\n",
       "        [  1571.95703706, -10888.20869575],\n",
       "        [  1529.82853808, -10946.07269917],\n",
       "        [  1598.88003641, -11064.22869633],\n",
       "        [  1565.41703722, -10896.27469556],\n",
       "        [  1585.74553673, -11070.65969618],\n",
       "        [  1557.67803741, -10928.79619959],\n",
       "        [  1550.42953758, -11056.16269653],\n",
       "        [  1671.20153467, -11047.66069673],\n",
       "        [  1626.51153575, -10912.33719999],\n",
       "        [  1644.33303532, -10923.01919973],\n",
       "        [  1498.07003403, -10941.60369928],\n",
       "        [  1571.95703706, -10922.41969974],\n",
       "        [  1622.75103584, -11076.49119604],\n",
       "        [  1658.39403498, -10943.23869924],\n",
       "        [  1559.31303737, -10997.08469795],\n",
       "        [  1632.8335356 , -10890.6066957 ],\n",
       "        [  1528.9565381 , -10924.2181997 ],\n",
       "        [  1544.38003772, -10962.15019879],\n",
       "        [  1496.52903888, -10992.12519807],\n",
       "        [  1663.02653487, -11032.56419709],\n",
       "        [  1651.90853514, -11052.67469661],\n",
       "        [  1657.740035  , -10915.17119992],\n",
       "        [  1541.60053779, -10907.26870011],\n",
       "        [  1521.92603827, -11002.15319782],\n",
       "        [  1610.87003613, -10894.36719561],\n",
       "        [  1622.96903583, -10930.86719954],\n",
       "        [  1635.50403553, -11064.71919632],\n",
       "        [  1612.55953608, -10924.43619969],\n",
       "        [  1539.96553783, -11041.88369687],\n",
       "        [  1523.94253822, -10932.17519951],\n",
       "        [  1558.60453738, -11058.39719647],\n",
       "        [  1586.29053672, -11005.42319775],\n",
       "        [  1552.88203752, -10918.71369983],\n",
       "        [  1582.8570368 , -10932.22969951],\n",
       "        [  1494.03703412, -11029.56669717],\n",
       "        [  1526.39503816, -11049.29569669]]),\n",
       " ArrayView([[-0.3077751 , -0.43280727,  3.7756994 , ...,  1.9689927 ,\n",
       "             -0.32283673, -0.15858787],\n",
       "            [-0.3077751 , -0.43280727,  2.5842752 , ...,  1.2263724 ,\n",
       "             -0.32283673, -0.15858787],\n",
       "            [-0.3077751 , -0.43280727, -0.43380988, ..., -0.53142697,\n",
       "             -0.32283673, -0.15858787],\n",
       "            ...,\n",
       "            [ 3.9316652 , -0.43280727, -0.43380988, ...,  1.3900081 ,\n",
       "             -0.32283673, -0.15858787],\n",
       "            [-0.3077751 , -0.43280727, -0.43380988, ..., -0.53142697,\n",
       "             -0.32283673, -0.15858787],\n",
       "            [-0.3077751 , -0.43280727, -0.43380988, ..., -0.53142697,\n",
       "             -0.32283673, -0.15858787]], dtype=float32),\n",
       " array([[ 18.89246   ,  -7.8724885 ],\n",
       "        [  3.269108  ,   2.5687957 ],\n",
       "        [  0.62583494,  -8.384888  ],\n",
       "        [ -5.341048  ,  14.861167  ],\n",
       "        [ -1.92481   ,  -7.6973968 ],\n",
       "        [ -0.07300501,  10.406919  ],\n",
       "        [  9.232348  ,  -3.1947715 ],\n",
       "        [ 12.027211  ,  -3.1064465 ],\n",
       "        [ 11.359305  ,  -7.851377  ],\n",
       "        [ 10.968288  , -14.891005  ],\n",
       "        [  8.740383  ,  -1.2143338 ],\n",
       "        [-21.773565  ,   0.974317  ],\n",
       "        [-11.692947  ,   4.405701  ],\n",
       "        [ 15.088957  , -20.625978  ],\n",
       "        [-15.567964  ,  16.817184  ],\n",
       "        [ -4.137413  , -13.010883  ],\n",
       "        [ 23.590746  ,  -8.371495  ],\n",
       "        [ 14.34189   ,  -4.850592  ],\n",
       "        [ -4.5174174 ,  -8.73691   ],\n",
       "        [-14.390679  ,  10.583577  ],\n",
       "        [ -1.1503048 ,  -6.626029  ],\n",
       "        [  2.5693953 , -10.742705  ],\n",
       "        [  3.4566798 ,  -1.7911329 ],\n",
       "        [ 13.862366  , -10.5903015 ],\n",
       "        [ -8.057493  ,  16.51877   ],\n",
       "        [-12.454074  ,   7.467543  ],\n",
       "        [ 13.068814  ,  -0.037971  ],\n",
       "        [  6.2850876 ,   3.7190948 ],\n",
       "        [ -7.8756976 ,  -1.2625024 ],\n",
       "        [ -2.6312227 ,  -8.151148  ],\n",
       "        [ -6.9456024 , -10.535583  ],\n",
       "        [-11.946466  ,  -0.25155   ],\n",
       "        [ 10.546717  , -10.503632  ],\n",
       "        [  3.912754  , -15.199132  ],\n",
       "        [ 10.9594965 ,   1.8882866 ],\n",
       "        [-14.825741  ,  10.190001  ],\n",
       "        [  6.6590605 ,  10.330982  ],\n",
       "        [ 13.277969  ,  10.706252  ],\n",
       "        [  2.9772022 ,  -0.40158918],\n",
       "        [ 10.984077  ,  -9.349778  ],\n",
       "        [ -0.9457438 ,   0.9312054 ],\n",
       "        [ -2.9798872 ,   2.3665872 ],\n",
       "        [ 13.595331  , -10.691067  ],\n",
       "        [-16.04628   ,   1.4326026 ],\n",
       "        [  9.946022  ,  -2.6402152 ],\n",
       "        [ -4.8018813 , -10.891648  ],\n",
       "        [ -0.9457333 ,   1.6039296 ],\n",
       "        [-12.804911  ,   2.6175601 ],\n",
       "        [ 13.55534   ,  -6.731904  ],\n",
       "        [ -3.2341177 ,  -9.559399  ]], dtype=float32),\n",
       " array([[ -1.8353392 ,  -8.002904  , -13.110403  , ..., -17.448515  ,\n",
       "           0.9602624 ,   2.2615445 ],\n",
       "        [ -7.0944858 ,  -4.2377496 ,  15.565738  , ...,  -1.6488085 ,\n",
       "         -22.755768  ,   9.719034  ],\n",
       "        [  8.215441  , -14.011234  , -12.711771  , ...,   8.483707  ,\n",
       "          26.150259  ,  10.136014  ],\n",
       "        ...,\n",
       "        [ -0.14887951, -10.728919  ,   2.2043264 , ...,  -8.861861  ,\n",
       "          12.094931  ,   5.437733  ],\n",
       "        [ 13.95119   ,  -8.569176  , -24.64531   , ...,  -2.5354226 ,\n",
       "           6.1196847 ,   5.0858026 ],\n",
       "        [  0.8374562 ,  -3.0599291 ,   0.5111096 , ...,  -9.022908  ,\n",
       "          -5.602142  ,  10.258237  ]], dtype=float32))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_coords, true_gene_expressions, pred_coords, pred_gene_expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = create_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.model == 'gaussian':\n",
    "    model = GaussianVAE(args).to(args.device)\n",
    "elif args.model == 'flow':\n",
    "    model = FlowVAE(args).to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianVAE(\n",
       "  (encoder): PointNetEncoder(\n",
       "    (conv1): Conv1d(376, 32, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
       "    (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (fc1_m): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (fc2_m): Linear(in_features=32, out_features=256, bias=True)\n",
       "    (fc_bn1_m): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (fc1_v): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (fc2_v): Linear(in_features=32, out_features=256, bias=True)\n",
       "    (fc_bn1_v): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (diffusion): DiffusionPoint(\n",
       "    (net): PointwiseNet(\n",
       "      (layers): ModuleList(\n",
       "        (0): ConcatSquashLinear(\n",
       "          (_layer): Linear(in_features=376, out_features=128, bias=True)\n",
       "          (_hyper_bias): Linear(in_features=259, out_features=128, bias=False)\n",
       "          (_hyper_gate): Linear(in_features=259, out_features=128, bias=True)\n",
       "        )\n",
       "        (1): ConcatSquashLinear(\n",
       "          (_layer): Linear(in_features=128, out_features=376, bias=True)\n",
       "          (_hyper_bias): Linear(in_features=259, out_features=376, bias=False)\n",
       "          (_hyper_gate): Linear(in_features=259, out_features=376, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (var_sched): VarianceSchedule()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters:  390720\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"Total number of parameters: \", total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer and scheduler\n",
    "optimizer = torch.optim.Adam(model.parameters(), \n",
    "    lr=args.lr, \n",
    "    weight_decay=args.weight_decay\n",
    ")\n",
    "\n",
    "scheduler = get_linear_scheduler(\n",
    "    optimizer,\n",
    "    start_epoch=args.sched_start_epoch,\n",
    "    end_epoch=args.sched_end_epoch,\n",
    "    start_lr=args.lr,\n",
    "    end_lr=args.end_lr\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_prior: 43.215293884277344 loss_recons: 1.428468108177185\n",
      "loss_prior: 45.11161422729492 loss_recons: 1.4219812154769897\n",
      "loss_prior: 40.19297409057617 loss_recons: 1.6297687292099\n",
      "loss_prior: 38.26530838012695 loss_recons: 1.3491694927215576\n",
      "loss_prior: 37.44154739379883 loss_recons: 1.4217432737350464\n",
      "loss_prior: 34.441383361816406 loss_recons: 1.4384878873825073\n",
      "loss_prior: 34.64091110229492 loss_recons: 1.3276280164718628\n",
      "loss_prior: 33.862632751464844 loss_recons: 1.4400230646133423\n",
      "loss_prior: 31.70770263671875 loss_recons: 1.5533256530761719\n",
      "loss_prior: 29.685216903686523 loss_recons: 1.1273138523101807\n",
      "loss_prior: 28.880537033081055 loss_recons: 1.2874871492385864\n",
      "loss_prior: 25.32862663269043 loss_recons: 1.3613570928573608\n",
      "loss_prior: 27.468555450439453 loss_recons: 1.2836376428604126\n",
      "loss_prior: 23.109333038330078 loss_recons: 1.463850498199463\n",
      "loss_prior: 20.107534408569336 loss_recons: 1.2300490140914917\n",
      "loss_prior: 18.27768325805664 loss_recons: 1.561371922492981\n",
      "loss_prior: 18.68169403076172 loss_recons: 1.4472967386245728\n",
      "loss_prior: 16.607324600219727 loss_recons: 1.1829010248184204\n",
      "loss_prior: 14.461090087890625 loss_recons: 1.365041971206665\n",
      "loss_prior: 17.14580726623535 loss_recons: 1.3691022396087646\n",
      "loss_prior: 12.97057819366455 loss_recons: 1.043429970741272\n",
      "loss_prior: 13.278254508972168 loss_recons: 1.0560975074768066\n",
      "loss_prior: 9.853376388549805 loss_recons: 1.2280317544937134\n",
      "loss_prior: 11.450515747070312 loss_recons: 1.4038031101226807\n",
      "loss_prior: 9.16260814666748 loss_recons: 1.2897933721542358\n",
      "loss_prior: 9.631869316101074 loss_recons: 0.9310686588287354\n",
      "loss_prior: 7.423016548156738 loss_recons: 1.200660228729248\n",
      "loss_prior: 5.894362926483154 loss_recons: 1.3403589725494385\n",
      "loss_prior: 7.51593542098999 loss_recons: 1.253511905670166\n",
      "loss_prior: 4.345862865447998 loss_recons: 1.1479980945587158\n",
      "loss_prior: 4.387618541717529 loss_recons: 1.0209702253341675\n",
      "loss_prior: 4.116065979003906 loss_recons: 1.381946086883545\n",
      "loss_prior: 5.168558597564697 loss_recons: 1.4356493949890137\n",
      "loss_prior: 3.191352605819702 loss_recons: 1.096218228340149\n",
      "loss_prior: 2.976985216140747 loss_recons: 1.2361382246017456\n",
      "loss_prior: 3.627460479736328 loss_recons: 1.3513725996017456\n",
      "loss_prior: 4.304973602294922 loss_recons: 1.1309146881103516\n",
      "loss_prior: 2.7958824634552 loss_recons: 1.2951674461364746\n",
      "loss_prior: 3.2926323413848877 loss_recons: 1.1281912326812744\n",
      "loss_prior: 2.3551290035247803 loss_recons: 1.1952033042907715\n",
      "loss_prior: 1.7903099060058594 loss_recons: 1.3552545309066772\n",
      "loss_prior: 1.5556505918502808 loss_recons: 1.2119344472885132\n",
      "loss_prior: 1.4223411083221436 loss_recons: 1.1068793535232544\n",
      "loss_prior: 1.8085161447525024 loss_recons: 1.1751835346221924\n",
      "loss_prior: 1.7780388593673706 loss_recons: 1.147387981414795\n",
      "loss_prior: 1.5152291059494019 loss_recons: 1.3490545749664307\n",
      "loss_prior: 1.1429978609085083 loss_recons: 1.1515249013900757\n",
      "loss_prior: 1.185895323753357 loss_recons: 1.0640922784805298\n",
      "loss_prior: 0.8267233967781067 loss_recons: 1.1808134317398071\n",
      "loss_prior: 0.8915960192680359 loss_recons: 1.0786231756210327\n",
      "loss_prior: 1.2320612668991089 loss_recons: 1.1035466194152832\n",
      "loss_prior: 1.1275144815444946 loss_recons: 1.1139740943908691\n",
      "loss_prior: 0.883267879486084 loss_recons: 1.225993275642395\n",
      "loss_prior: 0.890882670879364 loss_recons: 1.0493721961975098\n",
      "loss_prior: 0.5417594313621521 loss_recons: 1.2577663660049438\n",
      "loss_prior: 0.6671366691589355 loss_recons: 1.2122999429702759\n",
      "loss_prior: 0.39594417810440063 loss_recons: 0.9172402620315552\n",
      "loss_prior: 1.0318479537963867 loss_recons: 1.0239096879959106\n",
      "loss_prior: 0.6153846979141235 loss_recons: 1.0404094457626343\n",
      "loss_prior: 0.4716796875 loss_recons: 1.1331909894943237\n",
      "loss_prior: 0.4086631238460541 loss_recons: 0.9445500373840332\n",
      "loss_prior: 0.771590530872345 loss_recons: 1.1410189867019653\n",
      "loss_prior: 0.44471874833106995 loss_recons: 0.9571608901023865\n",
      "loss_prior: 0.4661715030670166 loss_recons: 0.698053777217865\n",
      "loss_prior: 0.343056857585907 loss_recons: 1.3275172710418701\n",
      "loss_prior: 0.2995743453502655 loss_recons: 1.2169201374053955\n",
      "loss_prior: 0.3836445212364197 loss_recons: 1.3314592838287354\n",
      "loss_prior: 0.3593056797981262 loss_recons: 1.0246033668518066\n",
      "loss_prior: 0.22676169872283936 loss_recons: 1.3826208114624023\n",
      "loss_prior: 0.27315616607666016 loss_recons: 0.9903250932693481\n",
      "loss_prior: 0.520119845867157 loss_recons: 1.218338131904602\n",
      "loss_prior: 0.2819027304649353 loss_recons: 1.2837889194488525\n",
      "loss_prior: 0.24158143997192383 loss_recons: 0.9817001223564148\n",
      "loss_prior: 0.3318668305873871 loss_recons: 0.8352185487747192\n",
      "loss_prior: 0.20189225673675537 loss_recons: 0.79831862449646\n",
      "loss_prior: 0.22751669585704803 loss_recons: 1.1304234266281128\n",
      "loss_prior: 0.29295626282691956 loss_recons: 0.7820091247558594\n",
      "loss_prior: 0.18758156895637512 loss_recons: 0.9836499094963074\n",
      "loss_prior: 0.15154753625392914 loss_recons: 1.2249011993408203\n",
      "loss_prior: 0.17951177060604095 loss_recons: 0.9452878832817078\n",
      "loss_prior: 0.12314329296350479 loss_recons: 1.0756847858428955\n",
      "loss_prior: 0.1675393134355545 loss_recons: 1.1431692838668823\n",
      "loss_prior: 0.17331016063690186 loss_recons: 1.0690193176269531\n",
      "loss_prior: 0.17239277064800262 loss_recons: 0.8947159051895142\n",
      "loss_prior: 0.13699734210968018 loss_recons: 1.0610363483428955\n",
      "loss_prior: 0.32275962829589844 loss_recons: 1.2117383480072021\n",
      "loss_prior: 0.13550414144992828 loss_recons: 0.9541494250297546\n",
      "loss_prior: 0.1772937774658203 loss_recons: 0.8814889192581177\n",
      "loss_prior: 0.22056885063648224 loss_recons: 0.9846642017364502\n",
      "loss_prior: 0.1383742392063141 loss_recons: 0.9066537618637085\n",
      "loss_prior: 0.2387837916612625 loss_recons: 1.0740834474563599\n",
      "loss_prior: 0.1221308633685112 loss_recons: 0.9145556688308716\n",
      "loss_prior: 0.12554219365119934 loss_recons: 1.0941522121429443\n",
      "loss_prior: 0.10694646090269089 loss_recons: 0.763102114200592\n",
      "loss_prior: 0.10312735289335251 loss_recons: 0.8427438139915466\n",
      "loss_prior: 0.19792680442333221 loss_recons: 1.178044319152832\n",
      "loss_prior: 0.10597258061170578 loss_recons: 1.055516242980957\n",
      "loss_prior: 0.09721042215824127 loss_recons: 1.137214183807373\n",
      "loss_prior: 0.08092144876718521 loss_recons: 1.096611738204956\n",
      "loss_prior: 0.08784715086221695 loss_recons: 1.0122010707855225\n",
      "loss_prior: 0.14232870936393738 loss_recons: 1.063672661781311\n",
      "loss_prior: 0.08679798990488052 loss_recons: 0.9149423837661743\n",
      "loss_prior: 0.12904135882854462 loss_recons: 1.1356816291809082\n",
      "loss_prior: 0.1925308257341385 loss_recons: 0.6935539245605469\n",
      "loss_prior: 0.07804319262504578 loss_recons: 0.7467340230941772\n",
      "loss_prior: 0.14140653610229492 loss_recons: 0.9287025928497314\n",
      "loss_prior: 0.12138936668634415 loss_recons: 0.9112025499343872\n",
      "loss_prior: 0.08502837270498276 loss_recons: 1.0810214281082153\n",
      "loss_prior: 0.132557675242424 loss_recons: 0.9021700024604797\n",
      "loss_prior: 0.071277916431427 loss_recons: 0.8599758744239807\n",
      "loss_prior: 0.09771890938282013 loss_recons: 1.13558030128479\n",
      "loss_prior: 0.07494378089904785 loss_recons: 1.146096110343933\n",
      "loss_prior: 0.10340005159378052 loss_recons: 1.0621111392974854\n",
      "loss_prior: 0.1021404042840004 loss_recons: 1.0468107461929321\n",
      "loss_prior: 0.06824284791946411 loss_recons: 0.9630926251411438\n",
      "loss_prior: 0.1298876404762268 loss_recons: 1.0424445867538452\n",
      "loss_prior: 0.15938487648963928 loss_recons: 1.1648447513580322\n",
      "loss_prior: 0.11237511783838272 loss_recons: 1.0090243816375732\n",
      "loss_prior: 0.056378912180662155 loss_recons: 0.9938749074935913\n",
      "loss_prior: 0.06323444098234177 loss_recons: 0.9757619500160217\n",
      "loss_prior: 0.04816417023539543 loss_recons: 1.191100001335144\n",
      "loss_prior: 0.0661739706993103 loss_recons: 1.1840649843215942\n",
      "loss_prior: 0.06315045058727264 loss_recons: 1.1435898542404175\n",
      "loss_prior: 0.06959152966737747 loss_recons: 0.9050244092941284\n",
      "loss_prior: 0.036356329917907715 loss_recons: 0.9070227742195129\n",
      "loss_prior: 0.035608261823654175 loss_recons: 1.099453330039978\n",
      "loss_prior: 0.06496893614530563 loss_recons: 0.927117645740509\n",
      "loss_prior: 0.06054404005408287 loss_recons: 1.0114569664001465\n",
      "loss_prior: 0.05808502435684204 loss_recons: 1.2197283506393433\n",
      "loss_prior: 0.04174678400158882 loss_recons: 0.735967755317688\n",
      "loss_prior: 0.048948079347610474 loss_recons: 0.8155997395515442\n",
      "loss_prior: 0.042020972818136215 loss_recons: 0.9188718199729919\n",
      "loss_prior: 0.03362486511468887 loss_recons: 0.9497082829475403\n",
      "loss_prior: 0.06375867128372192 loss_recons: 0.8644492626190186\n",
      "loss_prior: 0.037095166742801666 loss_recons: 0.9294348359107971\n",
      "loss_prior: 0.051414430141448975 loss_recons: 0.7845942974090576\n",
      "loss_prior: 0.03171544894576073 loss_recons: 1.1006715297698975\n",
      "loss_prior: 0.07371342182159424 loss_recons: 1.165588140487671\n",
      "loss_prior: 0.039380233734846115 loss_recons: 1.0505064725875854\n",
      "loss_prior: 0.028617030009627342 loss_recons: 0.8884150385856628\n",
      "loss_prior: 0.03711797669529915 loss_recons: 1.0853501558303833\n",
      "loss_prior: 0.05495439097285271 loss_recons: 0.8307862877845764\n",
      "loss_prior: 0.020931411534547806 loss_recons: 1.0761117935180664\n",
      "loss_prior: 0.03701382502913475 loss_recons: 0.9922742247581482\n",
      "loss_prior: 0.03742719814181328 loss_recons: 0.8815855979919434\n",
      "loss_prior: 0.03314201906323433 loss_recons: 0.8519154787063599\n",
      "loss_prior: 0.04269454628229141 loss_recons: 0.9161844849586487\n",
      "loss_prior: 0.028200024738907814 loss_recons: 1.089228630065918\n",
      "loss_prior: 0.02401926927268505 loss_recons: 0.9290782809257507\n",
      "loss_prior: 0.03681931272149086 loss_recons: 0.8484166860580444\n",
      "loss_prior: 0.04384903237223625 loss_recons: 1.0324229001998901\n",
      "loss_prior: 0.03134777769446373 loss_recons: 0.9786761999130249\n",
      "loss_prior: 0.028223996981978416 loss_recons: 1.0074350833892822\n",
      "loss_prior: 0.024804670363664627 loss_recons: 0.7865294218063354\n",
      "loss_prior: 0.027542252093553543 loss_recons: 0.8815950751304626\n",
      "loss_prior: 0.017418688163161278 loss_recons: 1.253636121749878\n",
      "loss_prior: 0.01910318247973919 loss_recons: 0.8890125155448914\n",
      "loss_prior: 0.020074263215065002 loss_recons: 1.0651838779449463\n",
      "loss_prior: 0.023473462089896202 loss_recons: 0.8203304409980774\n",
      "loss_prior: 0.02520936168730259 loss_recons: 1.0512182712554932\n",
      "loss_prior: 0.020164767280220985 loss_recons: 0.9196968078613281\n",
      "loss_prior: 0.01996663585305214 loss_recons: 0.6884258389472961\n",
      "loss_prior: 0.020994266495108604 loss_recons: 0.9501420855522156\n",
      "loss_prior: 0.02305835485458374 loss_recons: 1.038637638092041\n",
      "loss_prior: 0.026829561218619347 loss_recons: 1.0219082832336426\n",
      "loss_prior: 0.027601271867752075 loss_recons: 0.9594283699989319\n",
      "loss_prior: 0.023733431473374367 loss_recons: 1.016338586807251\n",
      "loss_prior: 0.02632237784564495 loss_recons: 1.0082865953445435\n",
      "loss_prior: 0.06505515426397324 loss_recons: 0.7779462933540344\n",
      "loss_prior: 0.020569121465086937 loss_recons: 0.8817624449729919\n",
      "loss_prior: 0.025122320279479027 loss_recons: 0.918332576751709\n",
      "loss_prior: 0.03122040629386902 loss_recons: 0.8760564923286438\n",
      "loss_prior: 0.015241074375808239 loss_recons: 1.0696384906768799\n",
      "loss_prior: 0.01632176712155342 loss_recons: 0.9766948223114014\n",
      "loss_prior: 0.0221034474670887 loss_recons: 1.2067477703094482\n",
      "loss_prior: 0.01951250433921814 loss_recons: 0.8670471906661987\n",
      "loss_prior: 0.02516934834420681 loss_recons: 0.8071949481964111\n",
      "loss_prior: 0.01987270824611187 loss_recons: 0.7815574407577515\n",
      "loss_prior: 0.015177018009126186 loss_recons: 1.0226483345031738\n",
      "loss_prior: 0.040966469794511795 loss_recons: 0.9533600807189941\n",
      "loss_prior: 0.013266632333397865 loss_recons: 1.056566596031189\n",
      "loss_prior: 0.02431553043425083 loss_recons: 0.8489212989807129\n",
      "loss_prior: 0.01636791042983532 loss_recons: 1.1878845691680908\n",
      "loss_prior: 0.014717183075845242 loss_recons: 0.8923617005348206\n",
      "loss_prior: 0.021492812782526016 loss_recons: 1.1322356462478638\n",
      "loss_prior: 0.02040613256394863 loss_recons: 0.9361639618873596\n",
      "loss_prior: 0.013690155930817127 loss_recons: 0.8275784254074097\n",
      "loss_prior: 0.014593389816582203 loss_recons: 0.8495256900787354\n",
      "loss_prior: 0.014956990256905556 loss_recons: 0.7793376445770264\n",
      "loss_prior: 0.01685275137424469 loss_recons: 1.0592437982559204\n",
      "loss_prior: 0.016714943572878838 loss_recons: 0.9101263284683228\n",
      "loss_prior: 0.01919500343501568 loss_recons: 0.9691400527954102\n",
      "loss_prior: 0.01611335016787052 loss_recons: 0.7520488500595093\n",
      "loss_prior: 0.015592616982758045 loss_recons: 0.9413834810256958\n",
      "loss_prior: 0.1363406479358673 loss_recons: 0.7856974005699158\n",
      "loss_prior: 0.016013139858841896 loss_recons: 0.9041599035263062\n",
      "loss_prior: 0.022744664922356606 loss_recons: 0.9361395835876465\n",
      "loss_prior: 0.02114013209939003 loss_recons: 0.9333076477050781\n",
      "loss_prior: 0.016543088480830193 loss_recons: 0.9028152227401733\n",
      "loss_prior: 0.01913248561322689 loss_recons: 1.0012760162353516\n",
      "loss_prior: 0.01633426547050476 loss_recons: 1.0821200609207153\n",
      "loss_prior: 0.027217641472816467 loss_recons: 0.8715883493423462\n",
      "loss_prior: 0.0284128375351429 loss_recons: 0.9669808745384216\n",
      "loss_prior: 0.018282491713762283 loss_recons: 0.8506397008895874\n",
      "loss_prior: 0.013545584864914417 loss_recons: 0.7771996855735779\n",
      "loss_prior: 0.01648052968084812 loss_recons: 1.0410823822021484\n",
      "loss_prior: 0.015818223357200623 loss_recons: 0.8362807631492615\n",
      "loss_prior: 0.032836731523275375 loss_recons: 0.7616389393806458\n",
      "loss_prior: 0.012946235947310925 loss_recons: 1.044947862625122\n",
      "loss_prior: 0.015525147318840027 loss_recons: 0.9866282343864441\n",
      "loss_prior: 0.01304143387824297 loss_recons: 1.1023974418640137\n",
      "loss_prior: 0.01792137138545513 loss_recons: 1.0408672094345093\n",
      "loss_prior: 0.01281809527426958 loss_recons: 0.9062724113464355\n",
      "loss_prior: 0.013729557394981384 loss_recons: 0.8886535167694092\n",
      "loss_prior: 0.015755388885736465 loss_recons: 0.9888096451759338\n",
      "loss_prior: 0.011406267061829567 loss_recons: 0.9265688061714172\n",
      "loss_prior: 0.011131486855447292 loss_recons: 0.7282571196556091\n",
      "loss_prior: 0.012505394406616688 loss_recons: 0.8308537006378174\n",
      "loss_prior: 0.03994322940707207 loss_recons: 1.0125383138656616\n",
      "loss_prior: 0.016001835465431213 loss_recons: 0.9026333093643188\n",
      "loss_prior: 0.019286412745714188 loss_recons: 1.1021267175674438\n",
      "loss_prior: 0.010366675443947315 loss_recons: 0.7492839097976685\n",
      "loss_prior: 0.015538281761109829 loss_recons: 0.7421057224273682\n",
      "loss_prior: 0.01777854934334755 loss_recons: 0.9679768681526184\n",
      "loss_prior: 0.011071735993027687 loss_recons: 1.053802728652954\n",
      "loss_prior: 0.009507066570222378 loss_recons: 0.7108134031295776\n",
      "loss_prior: 0.011811462230980396 loss_recons: 0.9335747957229614\n",
      "loss_prior: 0.011229068040847778 loss_recons: 0.8871315717697144\n",
      "loss_prior: 0.011715823784470558 loss_recons: 0.991943359375\n",
      "loss_prior: 0.01297767460346222 loss_recons: 0.8989576101303101\n",
      "loss_prior: 0.012629128061234951 loss_recons: 0.7619377970695496\n",
      "loss_prior: 0.012088901363313198 loss_recons: 1.023780345916748\n",
      "loss_prior: 0.010705373249948025 loss_recons: 1.0199341773986816\n",
      "loss_prior: 0.009594607166945934 loss_recons: 0.8891943097114563\n",
      "loss_prior: 0.008829972706735134 loss_recons: 0.9386009573936462\n",
      "loss_prior: 0.012923222966492176 loss_recons: 0.9190217852592468\n",
      "loss_prior: 0.01139680203050375 loss_recons: 0.8122569918632507\n",
      "loss_prior: 0.009183946065604687 loss_recons: 0.875943124294281\n",
      "loss_prior: 0.011329591274261475 loss_recons: 0.8271112442016602\n",
      "loss_prior: 0.009204340167343616 loss_recons: 0.8191789984703064\n",
      "loss_prior: 0.009204322472214699 loss_recons: 0.7304856181144714\n",
      "loss_prior: 0.010893315076828003 loss_recons: 0.8906466960906982\n",
      "loss_prior: 0.01284568291157484 loss_recons: 1.1973507404327393\n",
      "loss_prior: 0.013202718459069729 loss_recons: 1.0393227338790894\n",
      "loss_prior: 0.01268590148538351 loss_recons: 1.0092403888702393\n",
      "loss_prior: 0.010165748186409473 loss_recons: 0.9479665756225586\n",
      "loss_prior: 0.007371020503342152 loss_recons: 0.8255570530891418\n",
      "loss_prior: 0.00993723887950182 loss_recons: 0.8647506237030029\n",
      "loss_prior: 0.007692283485084772 loss_recons: 0.8137326836585999\n",
      "loss_prior: 0.011531094089150429 loss_recons: 1.0633690357208252\n",
      "loss_prior: 0.006700641009956598 loss_recons: 0.8105155229568481\n",
      "loss_prior: 0.006439840886741877 loss_recons: 0.9317237138748169\n",
      "loss_prior: 0.008201993070542812 loss_recons: 0.8662403225898743\n",
      "loss_prior: 0.011288920417428017 loss_recons: 0.808877170085907\n",
      "loss_prior: 0.00607014587149024 loss_recons: 1.1264076232910156\n",
      "loss_prior: 0.009343010373413563 loss_recons: 0.8279291987419128\n",
      "loss_prior: 0.010345629416406155 loss_recons: 0.9883529543876648\n",
      "loss_prior: 0.017855573445558548 loss_recons: 1.2063016891479492\n",
      "loss_prior: 0.007605382706969976 loss_recons: 0.9475480914115906\n",
      "loss_prior: 0.06890564411878586 loss_recons: 1.1934285163879395\n",
      "loss_prior: 0.010726592503488064 loss_recons: 0.8175332546234131\n",
      "loss_prior: 0.01899135671555996 loss_recons: 0.803217351436615\n",
      "loss_prior: 0.011478188447654247 loss_recons: 1.0279470682144165\n",
      "loss_prior: 0.008683064952492714 loss_recons: 0.9176954030990601\n",
      "loss_prior: 0.01193360984325409 loss_recons: 0.7835599184036255\n",
      "loss_prior: 0.006471437402069569 loss_recons: 0.9398397207260132\n",
      "loss_prior: 0.01091157179325819 loss_recons: 0.8707739114761353\n",
      "loss_prior: 0.0120215630158782 loss_recons: 0.9151272177696228\n",
      "loss_prior: 0.008887514472007751 loss_recons: 0.9776233434677124\n",
      "loss_prior: 0.015660181641578674 loss_recons: 0.8571653962135315\n",
      "loss_prior: 0.013149184174835682 loss_recons: 0.9097445011138916\n",
      "loss_prior: 0.01942155323922634 loss_recons: 0.7764157056808472\n",
      "loss_prior: 0.01177246030420065 loss_recons: 0.7040963768959045\n",
      "loss_prior: 0.012523231096565723 loss_recons: 1.0577577352523804\n",
      "loss_prior: 0.007151311729103327 loss_recons: 0.9072791337966919\n",
      "loss_prior: 0.012797782197594643 loss_recons: 1.072474718093872\n",
      "loss_prior: 0.005780387204140425 loss_recons: 0.640048086643219\n",
      "loss_prior: 0.006236576940864325 loss_recons: 0.7234398126602173\n",
      "loss_prior: 0.013854989781975746 loss_recons: 1.0349690914154053\n",
      "loss_prior: 0.007794636767357588 loss_recons: 0.697353720664978\n",
      "loss_prior: 0.014733701944351196 loss_recons: 0.9373868107795715\n",
      "loss_prior: 0.007682118099182844 loss_recons: 1.078669548034668\n",
      "loss_prior: 0.012926814146339893 loss_recons: 0.9173628687858582\n",
      "loss_prior: 0.009250074625015259 loss_recons: 0.8281428813934326\n",
      "loss_prior: 0.008545899763703346 loss_recons: 0.9421522617340088\n",
      "loss_prior: 0.0076448856852948666 loss_recons: 1.0205681324005127\n",
      "loss_prior: 0.00809691846370697 loss_recons: 0.8308178782463074\n",
      "loss_prior: 0.01807236671447754 loss_recons: 0.9380184412002563\n",
      "loss_prior: 0.0093137351796031 loss_recons: 0.8109196424484253\n",
      "loss_prior: 0.0068501802161335945 loss_recons: 0.7987940311431885\n",
      "loss_prior: 0.014314839616417885 loss_recons: 1.0404150485992432\n",
      "loss_prior: 0.010176831856369972 loss_recons: 0.8185232281684875\n",
      "loss_prior: 0.0068855853751301765 loss_recons: 0.9309892654418945\n",
      "loss_prior: 0.007154432125389576 loss_recons: 0.936391294002533\n",
      "loss_prior: 0.011609303764998913 loss_recons: 0.9944850206375122\n",
      "loss_prior: 0.008987954817712307 loss_recons: 1.0734256505966187\n",
      "loss_prior: 0.007484367582947016 loss_recons: 0.9538002014160156\n",
      "loss_prior: 0.006539616268128157 loss_recons: 0.9127672910690308\n",
      "loss_prior: 0.006570917554199696 loss_recons: 0.9113237261772156\n",
      "loss_prior: 0.01065343338996172 loss_recons: 0.9394007325172424\n",
      "loss_prior: 0.008528145961463451 loss_recons: 0.7145142555236816\n",
      "loss_prior: 0.009042957797646523 loss_recons: 0.8978557586669922\n",
      "loss_prior: 0.006166324019432068 loss_recons: 0.9253301024436951\n",
      "loss_prior: 0.00843910314142704 loss_recons: 0.8325681090354919\n",
      "loss_prior: 0.006455171387642622 loss_recons: 0.8049300312995911\n",
      "loss_prior: 0.00898428913205862 loss_recons: 0.8950656652450562\n",
      "loss_prior: 0.009351426735520363 loss_recons: 0.8358209729194641\n",
      "loss_prior: 0.005982315633445978 loss_recons: 0.9579496383666992\n",
      "loss_prior: 0.007056513335555792 loss_recons: 1.0552271604537964\n",
      "loss_prior: 0.007077699992805719 loss_recons: 0.8734316825866699\n",
      "loss_prior: 0.004662889521569014 loss_recons: 1.1240707635879517\n",
      "loss_prior: 0.004700792022049427 loss_recons: 0.7535440325737\n",
      "loss_prior: 0.004767251200973988 loss_recons: 0.9756664633750916\n",
      "loss_prior: 0.006920740008354187 loss_recons: 0.9704725742340088\n",
      "loss_prior: 0.005682164337486029 loss_recons: 0.9162377119064331\n",
      "loss_prior: 0.004386794753372669 loss_recons: 1.0216103792190552\n",
      "loss_prior: 0.005119925830513239 loss_recons: 0.8533123731613159\n",
      "loss_prior: 0.005900436546653509 loss_recons: 0.7622243762016296\n",
      "loss_prior: 0.004981690552085638 loss_recons: 0.7172788977622986\n",
      "loss_prior: 0.011346394196152687 loss_recons: 0.6085660457611084\n",
      "loss_prior: 0.008742976002395153 loss_recons: 0.9812955260276794\n",
      "loss_prior: 0.008675056509673595 loss_recons: 0.8814581036567688\n",
      "loss_prior: 0.006510499399155378 loss_recons: 0.9410508275032043\n",
      "loss_prior: 0.009465071372687817 loss_recons: 0.9022597670555115\n",
      "loss_prior: 0.0038635374512523413 loss_recons: 0.70838463306427\n",
      "loss_prior: 0.0045580388978123665 loss_recons: 0.7615554928779602\n",
      "loss_prior: 0.010949871502816677 loss_recons: 0.9465394020080566\n",
      "loss_prior: 0.0047120600938797 loss_recons: 0.9438148736953735\n",
      "loss_prior: 0.004892304539680481 loss_recons: 0.817386269569397\n",
      "loss_prior: 0.00788456853479147 loss_recons: 0.9059965014457703\n",
      "loss_prior: 0.004900563042610884 loss_recons: 0.951812207698822\n",
      "loss_prior: 0.006993446033447981 loss_recons: 0.8108735084533691\n",
      "loss_prior: 0.004699307959526777 loss_recons: 1.0440195798873901\n",
      "loss_prior: 0.005233132746070623 loss_recons: 1.1703211069107056\n",
      "loss_prior: 0.005784887354820967 loss_recons: 1.0103148221969604\n",
      "loss_prior: 0.004908103030174971 loss_recons: 0.7424517869949341\n",
      "loss_prior: 0.0049889953806996346 loss_recons: 0.9889429807662964\n",
      "loss_prior: 0.005978751461952925 loss_recons: 1.1299983263015747\n",
      "loss_prior: 0.00397297739982605 loss_recons: 0.9643818736076355\n",
      "loss_prior: 0.011964348144829273 loss_recons: 1.0414578914642334\n",
      "loss_prior: 0.0049199433997273445 loss_recons: 0.964953601360321\n",
      "loss_prior: 0.00671981880441308 loss_recons: 1.0014710426330566\n",
      "loss_prior: 0.004590338561683893 loss_recons: 0.840818464756012\n",
      "loss_prior: 0.006200033705681562 loss_recons: 0.8026666045188904\n",
      "loss_prior: 0.004880556371062994 loss_recons: 0.9270435571670532\n",
      "loss_prior: 0.0042770057916641235 loss_recons: 1.108655333518982\n",
      "loss_prior: 0.0064051090739667416 loss_recons: 0.8945431113243103\n",
      "loss_prior: 0.004621303174644709 loss_recons: 0.8639742732048035\n",
      "loss_prior: 0.008533978834748268 loss_recons: 1.0177514553070068\n",
      "loss_prior: 0.004334682133048773 loss_recons: 1.0478099584579468\n",
      "loss_prior: 0.005948788020759821 loss_recons: 0.7118481397628784\n",
      "loss_prior: 0.0032554329372942448 loss_recons: 0.6595607995986938\n",
      "loss_prior: 0.009264550171792507 loss_recons: 0.7679891586303711\n",
      "loss_prior: 0.004713315051048994 loss_recons: 0.9078731536865234\n",
      "loss_prior: 0.006189972162246704 loss_recons: 0.817246675491333\n",
      "loss_prior: 0.007038524840027094 loss_recons: 0.8381274938583374\n",
      "loss_prior: 0.003561341902241111 loss_recons: 0.7771457433700562\n",
      "loss_prior: 0.004433655645698309 loss_recons: 1.0392955541610718\n",
      "loss_prior: 0.007086858153343201 loss_recons: 0.9899810552597046\n",
      "loss_prior: 0.005446520633995533 loss_recons: 0.8409262895584106\n",
      "loss_prior: 0.0048857214860618114 loss_recons: 0.9898906350135803\n",
      "loss_prior: 0.004814645741134882 loss_recons: 1.1412816047668457\n",
      "loss_prior: 0.0038570971228182316 loss_recons: 1.041604995727539\n",
      "loss_prior: 0.019245220348238945 loss_recons: 1.1624892950057983\n",
      "loss_prior: 0.004633733537048101 loss_recons: 0.8047623038291931\n",
      "loss_prior: 0.00650698272511363 loss_recons: 1.0042914152145386\n",
      "loss_prior: 0.006286433432251215 loss_recons: 0.9461689591407776\n",
      "loss_prior: 0.010879245586693287 loss_recons: 0.8994644284248352\n",
      "loss_prior: 0.06302341818809509 loss_recons: 0.8651319742202759\n",
      "loss_prior: 0.005807382054626942 loss_recons: 0.8811026811599731\n",
      "loss_prior: 0.008594999089837074 loss_recons: 0.8057429790496826\n",
      "loss_prior: 0.008012676611542702 loss_recons: 0.9532629251480103\n",
      "loss_prior: 0.004621234722435474 loss_recons: 0.9992245435714722\n",
      "loss_prior: 0.004043325781822205 loss_recons: 0.8654489517211914\n",
      "loss_prior: 0.006602648179978132 loss_recons: 0.8633466362953186\n",
      "loss_prior: 0.010699686594307423 loss_recons: 0.7897977828979492\n",
      "loss_prior: 0.004656291101127863 loss_recons: 0.8282051086425781\n",
      "loss_prior: 0.012348410673439503 loss_recons: 0.8144571185112\n",
      "loss_prior: 0.00586437014862895 loss_recons: 0.9630001783370972\n",
      "loss_prior: 0.005271810572594404 loss_recons: 0.8103496432304382\n",
      "loss_prior: 0.005855506751686335 loss_recons: 0.850508987903595\n",
      "loss_prior: 0.004827210213989019 loss_recons: 0.9120787978172302\n",
      "loss_prior: 0.005008492153137922 loss_recons: 0.9482866525650024\n",
      "loss_prior: 0.004942742176353931 loss_recons: 0.8120724558830261\n",
      "loss_prior: 0.007776242680847645 loss_recons: 1.0720595121383667\n",
      "loss_prior: 0.004784399177879095 loss_recons: 1.1114001274108887\n",
      "loss_prior: 0.005030009429901838 loss_recons: 0.9465867280960083\n",
      "loss_prior: 0.00676017114892602 loss_recons: 0.9285153746604919\n",
      "loss_prior: 0.004636058118194342 loss_recons: 0.8954069018363953\n",
      "loss_prior: 0.004134136717766523 loss_recons: 1.0929133892059326\n",
      "loss_prior: 0.005915993358939886 loss_recons: 0.9209275841712952\n",
      "loss_prior: 0.004290211480110884 loss_recons: 0.8419802188873291\n",
      "loss_prior: 0.004327467177063227 loss_recons: 0.7975032329559326\n",
      "loss_prior: 0.0034216404892504215 loss_recons: 0.8730817437171936\n",
      "loss_prior: 0.005520674865692854 loss_recons: 0.9328719973564148\n",
      "loss_prior: 0.0037381500005722046 loss_recons: 0.8838090896606445\n",
      "loss_prior: 0.003952792380005121 loss_recons: 1.0907855033874512\n",
      "loss_prior: 0.004108816385269165 loss_recons: 0.8343373537063599\n",
      "loss_prior: 0.00450206408277154 loss_recons: 0.9035013318061829\n",
      "loss_prior: 0.0036936760880053043 loss_recons: 1.0297703742980957\n",
      "loss_prior: 0.006636512465775013 loss_recons: 0.8697307705879211\n",
      "loss_prior: 0.0042706760577857494 loss_recons: 0.7920400500297546\n",
      "loss_prior: 0.004266023635864258 loss_recons: 0.7286859750747681\n",
      "loss_prior: 0.003344103693962097 loss_recons: 1.094813346862793\n",
      "loss_prior: 0.005987680051475763 loss_recons: 0.7950171232223511\n",
      "loss_prior: 0.0033452033530920744 loss_recons: 0.9640712738037109\n",
      "loss_prior: 0.003454905701801181 loss_recons: 0.8041301965713501\n",
      "loss_prior: 0.005671569611877203 loss_recons: 0.9583587050437927\n",
      "loss_prior: 0.004409370012581348 loss_recons: 0.7766878008842468\n",
      "loss_prior: 0.003130316734313965 loss_recons: 0.9432721734046936\n",
      "loss_prior: 0.004991650581359863 loss_recons: 1.1729506254196167\n",
      "loss_prior: 0.0039119780994951725 loss_recons: 0.879962682723999\n",
      "loss_prior: 0.003765845438465476 loss_recons: 0.8677567839622498\n",
      "loss_prior: 0.006023630499839783 loss_recons: 1.0294915437698364\n",
      "loss_prior: 0.004325977060943842 loss_recons: 0.7774803638458252\n",
      "loss_prior: 0.00471763638779521 loss_recons: 0.8028311133384705\n",
      "loss_prior: 0.003527596592903137 loss_recons: 0.943794846534729\n",
      "loss_prior: 0.004016929771751165 loss_recons: 0.8057203888893127\n",
      "loss_prior: 0.0053218514658510685 loss_recons: 0.9932295083999634\n",
      "loss_prior: 0.0028162896633148193 loss_recons: 1.0240782499313354\n",
      "loss_prior: 0.002975067589432001 loss_recons: 0.9066851735115051\n",
      "loss_prior: 0.003466632915660739 loss_recons: 0.8417973518371582\n",
      "loss_prior: 0.004074710886925459 loss_recons: 0.6154636144638062\n",
      "loss_prior: 0.004088056273758411 loss_recons: 0.7374650835990906\n",
      "loss_prior: 0.004076451063156128 loss_recons: 0.7066599726676941\n",
      "loss_prior: 0.004916978068649769 loss_recons: 0.8100173473358154\n",
      "loss_prior: 0.0043275984935462475 loss_recons: 1.0796908140182495\n",
      "loss_prior: 0.0031943439971655607 loss_recons: 1.020680546760559\n",
      "loss_prior: 0.00405923742800951 loss_recons: 0.5979781150817871\n",
      "loss_prior: 0.004077750723809004 loss_recons: 0.8418611884117126\n",
      "loss_prior: 0.004767602775245905 loss_recons: 1.103226661682129\n",
      "loss_prior: 0.003601917764171958 loss_recons: 0.9962210655212402\n",
      "loss_prior: 0.0037476569414138794 loss_recons: 0.7398453950881958\n",
      "loss_prior: 0.002985349390655756 loss_recons: 0.8061445355415344\n",
      "loss_prior: 0.003217387245967984 loss_recons: 0.7496504187583923\n",
      "loss_prior: 0.0034223943948745728 loss_recons: 0.9821617007255554\n",
      "loss_prior: 0.003028294537216425 loss_recons: 0.9636806845664978\n",
      "loss_prior: 0.0032586962915956974 loss_recons: 0.8818876147270203\n",
      "loss_prior: 0.008045732975006104 loss_recons: 0.7995541095733643\n",
      "loss_prior: 0.0025932223070412874 loss_recons: 0.8199943900108337\n",
      "loss_prior: 0.003390371799468994 loss_recons: 0.7076351046562195\n",
      "loss_prior: 0.004625356290489435 loss_recons: 0.9259834289550781\n",
      "loss_prior: 0.0041231513023376465 loss_recons: 0.9387651085853577\n",
      "loss_prior: 0.003715223167091608 loss_recons: 1.1174498796463013\n",
      "loss_prior: 0.0028171183075755835 loss_recons: 0.6969854235649109\n",
      "loss_prior: 0.0025000988971441984 loss_recons: 0.848840594291687\n",
      "loss_prior: 0.0050470889545977116 loss_recons: 0.9284534454345703\n",
      "loss_prior: 0.004272911231964827 loss_recons: 0.7990726232528687\n",
      "loss_prior: 0.005418089218437672 loss_recons: 0.6308370232582092\n",
      "loss_prior: 0.00399243226274848 loss_recons: 0.8437000513076782\n",
      "loss_prior: 0.0030513168312609196 loss_recons: 0.8794447183609009\n",
      "loss_prior: 0.002968069864436984 loss_recons: 1.0531882047653198\n",
      "loss_prior: 0.003404766321182251 loss_recons: 1.0060912370681763\n",
      "loss_prior: 0.0032143741846084595 loss_recons: 0.9191893935203552\n",
      "loss_prior: 0.009344232268631458 loss_recons: 1.0987364053726196\n",
      "loss_prior: 0.006583485286682844 loss_recons: 0.8611759543418884\n",
      "loss_prior: 0.004752591252326965 loss_recons: 1.0389448404312134\n",
      "loss_prior: 0.006595134735107422 loss_recons: 0.6886046528816223\n",
      "loss_prior: 0.003399813314899802 loss_recons: 0.7629153728485107\n",
      "loss_prior: 0.0038260133005678654 loss_recons: 0.8337945938110352\n",
      "loss_prior: 0.004062158055603504 loss_recons: 0.8311936259269714\n",
      "loss_prior: 0.0050985426642000675 loss_recons: 0.7533005475997925\n",
      "loss_prior: 0.0035414190497249365 loss_recons: 1.0332074165344238\n",
      "loss_prior: 0.004294279497116804 loss_recons: 0.9584457874298096\n",
      "loss_prior: 0.003065243363380432 loss_recons: 0.9231247901916504\n",
      "loss_prior: 0.004321178887039423 loss_recons: 0.8115942478179932\n",
      "loss_prior: 0.004201078321784735 loss_recons: 0.8468506932258606\n",
      "loss_prior: 0.002701628254726529 loss_recons: 0.9710444211959839\n",
      "loss_prior: 0.003540626261383295 loss_recons: 0.7993684411048889\n",
      "loss_prior: 0.002877485705539584 loss_recons: 0.8607878684997559\n",
      "loss_prior: 0.0029454738833010197 loss_recons: 0.8700972199440002\n",
      "loss_prior: 0.0031062394846230745 loss_recons: 0.9536008834838867\n",
      "loss_prior: 0.003952920436859131 loss_recons: 1.0103070735931396\n",
      "loss_prior: 0.0029233605600893497 loss_recons: 0.9094031453132629\n",
      "loss_prior: 0.0027005316223949194 loss_recons: 0.8594047427177429\n",
      "loss_prior: 0.003368377685546875 loss_recons: 0.9512125849723816\n",
      "loss_prior: 0.005665433593094349 loss_recons: 0.8439845442771912\n",
      "loss_prior: 0.0036593854892998934 loss_recons: 1.0278297662734985\n",
      "loss_prior: 0.002811044454574585 loss_recons: 0.993172287940979\n",
      "loss_prior: 0.002584439469501376 loss_recons: 0.7903879284858704\n",
      "loss_prior: 0.013853633776307106 loss_recons: 0.8524296879768372\n",
      "loss_prior: 0.003534415503963828 loss_recons: 0.9844589829444885\n",
      "loss_prior: 0.011516979895532131 loss_recons: 0.8897989392280579\n",
      "loss_prior: 0.0033300668001174927 loss_recons: 0.8757420182228088\n",
      "loss_prior: 0.0035120665561407804 loss_recons: 0.8244624137878418\n",
      "loss_prior: 0.0031734914518892765 loss_recons: 1.0331147909164429\n",
      "loss_prior: 0.0026254565455019474 loss_recons: 0.9196049571037292\n",
      "loss_prior: 0.002695673843845725 loss_recons: 0.6730828881263733\n",
      "loss_prior: 0.002954792929813266 loss_recons: 0.9467875361442566\n",
      "loss_prior: 0.0022389055229723454 loss_recons: 0.9030855298042297\n",
      "loss_prior: 0.004172724671661854 loss_recons: 1.0550332069396973\n",
      "loss_prior: 0.0029715688433498144 loss_recons: 1.0041497945785522\n",
      "loss_prior: 0.0027381449472159147 loss_recons: 0.8099717497825623\n",
      "loss_prior: 0.0529504232108593 loss_recons: 1.1004389524459839\n",
      "loss_prior: 0.005859035532921553 loss_recons: 0.7771532535552979\n",
      "loss_prior: 0.006933078169822693 loss_recons: 0.9297494888305664\n",
      "loss_prior: 0.005761209409683943 loss_recons: 0.9238629937171936\n",
      "loss_prior: 0.005793771240860224 loss_recons: 1.1102638244628906\n",
      "loss_prior: 0.0037880928721278906 loss_recons: 1.0866286754608154\n",
      "loss_prior: 0.003904998302459717 loss_recons: 0.8836691975593567\n",
      "loss_prior: 0.00532880425453186 loss_recons: 0.935558021068573\n",
      "loss_prior: 0.007643717806786299 loss_recons: 0.8315474390983582\n",
      "loss_prior: 0.004645728971809149 loss_recons: 0.7424994707107544\n",
      "loss_prior: 0.008957651443779469 loss_recons: 0.8525097966194153\n",
      "loss_prior: 0.004629021976143122 loss_recons: 0.8715212345123291\n",
      "loss_prior: 0.004367986228317022 loss_recons: 0.9431242942810059\n",
      "loss_prior: 0.0033843161072582006 loss_recons: 0.9124506115913391\n",
      "loss_prior: 0.0063883960247039795 loss_recons: 1.0309759378433228\n",
      "loss_prior: 0.005256643984466791 loss_recons: 0.8624370098114014\n",
      "loss_prior: 0.005290439818054438 loss_recons: 0.8282519578933716\n",
      "loss_prior: 0.0040380689315497875 loss_recons: 1.0584840774536133\n",
      "loss_prior: 0.003710293909534812 loss_recons: 0.8644936680793762\n",
      "loss_prior: 0.008557415567338467 loss_recons: 0.9416905641555786\n",
      "loss_prior: 0.003841453930363059 loss_recons: 0.749454915523529\n",
      "loss_prior: 0.0031318217515945435 loss_recons: 0.8569924831390381\n",
      "loss_prior: 0.0029885501135140657 loss_recons: 0.7150698900222778\n",
      "loss_prior: 0.0034510137047618628 loss_recons: 1.1558350324630737\n",
      "loss_prior: 0.004787534475326538 loss_recons: 0.993155300617218\n",
      "loss_prior: 0.005073323845863342 loss_recons: 0.8262914419174194\n",
      "loss_prior: 0.0026613175868988037 loss_recons: 1.0980262756347656\n",
      "loss_prior: 0.0030758529901504517 loss_recons: 0.8585392236709595\n",
      "loss_prior: 0.0031601309310644865 loss_recons: 0.95597904920578\n",
      "loss_prior: 0.003223937703296542 loss_recons: 0.8595160245895386\n",
      "loss_prior: 0.003978171851485968 loss_recons: 0.8178243041038513\n",
      "loss_prior: 0.004199677612632513 loss_recons: 0.9459850192070007\n",
      "loss_prior: 0.0036794752813875675 loss_recons: 0.9221765995025635\n",
      "loss_prior: 0.003163436194881797 loss_recons: 1.0193943977355957\n",
      "loss_prior: 0.006826234050095081 loss_recons: 0.8475396037101746\n",
      "loss_prior: 0.003915697336196899 loss_recons: 0.8292694091796875\n",
      "loss_prior: 0.00394266564399004 loss_recons: 1.064085841178894\n",
      "loss_prior: 0.0029199065174907446 loss_recons: 1.0851616859436035\n",
      "loss_prior: 0.003991496749222279 loss_recons: 0.9427351951599121\n",
      "loss_prior: 0.006255227606743574 loss_recons: 1.0926812887191772\n",
      "loss_prior: 0.0021940141450613737 loss_recons: 0.9100146293640137\n",
      "loss_prior: 0.0036419301759451628 loss_recons: 0.784652590751648\n",
      "loss_prior: 0.0033158124424517155 loss_recons: 1.0303179025650024\n",
      "loss_prior: 0.0033080249559134245 loss_recons: 0.8459938168525696\n",
      "loss_prior: 0.0021614194847643375 loss_recons: 1.0370469093322754\n",
      "loss_prior: 0.0023013295140117407 loss_recons: 0.7421991229057312\n",
      "loss_prior: 0.0027505995240062475 loss_recons: 0.8862760663032532\n",
      "loss_prior: 0.0023079365491867065 loss_recons: 0.7985748648643494\n",
      "loss_prior: 0.0026607157196849585 loss_recons: 0.9052074551582336\n",
      "loss_prior: 0.007570028305053711 loss_recons: 0.9202578663825989\n",
      "loss_prior: 0.0024743080139160156 loss_recons: 0.9835951328277588\n",
      "loss_prior: 0.0038111747708171606 loss_recons: 1.0245672464370728\n",
      "loss_prior: 0.0045840563252568245 loss_recons: 0.7242612838745117\n",
      "loss_prior: 0.003123766276985407 loss_recons: 0.8622376918792725\n",
      "loss_prior: 0.0026460408698767424 loss_recons: 0.7544258236885071\n",
      "loss_prior: 0.0024657398462295532 loss_recons: 0.6719473600387573\n",
      "loss_prior: 0.012570628896355629 loss_recons: 0.6858753561973572\n",
      "loss_prior: 0.0037068009842187166 loss_recons: 0.9772518277168274\n",
      "loss_prior: 0.0035365193616598845 loss_recons: 1.071516990661621\n",
      "loss_prior: 0.0056386529467999935 loss_recons: 0.9542252421379089\n",
      "loss_prior: 0.0048949867486953735 loss_recons: 0.9476732015609741\n",
      "loss_prior: 0.003315222216770053 loss_recons: 0.9394124746322632\n",
      "loss_prior: 0.003189036389812827 loss_recons: 0.7513033151626587\n",
      "loss_prior: 0.0019454449648037553 loss_recons: 0.765219509601593\n",
      "loss_prior: 0.004368266556411982 loss_recons: 0.8745689392089844\n",
      "loss_prior: 0.0022557496558874846 loss_recons: 0.6209664344787598\n",
      "loss_prior: 0.0024150372482836246 loss_recons: 0.5721352696418762\n",
      "loss_prior: 0.0026516795624047518 loss_recons: 1.020436406135559\n",
      "loss_prior: 0.002778267953544855 loss_recons: 1.052901268005371\n",
      "loss_prior: 0.0020773529540747404 loss_recons: 0.9474766254425049\n",
      "loss_prior: 0.0015684396494179964 loss_recons: 0.9312227368354797\n",
      "loss_prior: 0.0036867379676550627 loss_recons: 0.8904168605804443\n",
      "loss_prior: 0.00256997044198215 loss_recons: 0.7477967143058777\n",
      "loss_prior: 0.003146091243252158 loss_recons: 0.7353879809379578\n",
      "loss_prior: 0.002578404499217868 loss_recons: 0.7805578112602234\n",
      "loss_prior: 0.0021260709036141634 loss_recons: 0.8766627907752991\n",
      "loss_prior: 0.0020415843464434147 loss_recons: 1.1067217588424683\n",
      "loss_prior: 0.002116450807079673 loss_recons: 0.7395914196968079\n",
      "loss_prior: 0.0053819953463971615 loss_recons: 0.885543704032898\n",
      "loss_prior: 0.0030311287846416235 loss_recons: 0.7864425778388977\n",
      "loss_prior: 0.005779069848358631 loss_recons: 0.7772062420845032\n",
      "loss_prior: 0.0015674055321142077 loss_recons: 0.7735879421234131\n",
      "loss_prior: 0.0034867078065872192 loss_recons: 1.0289949178695679\n",
      "loss_prior: 0.002670377492904663 loss_recons: 0.976021409034729\n",
      "loss_prior: 0.0022510469425469637 loss_recons: 0.8892343640327454\n",
      "loss_prior: 0.002661681268364191 loss_recons: 0.7592516541481018\n",
      "loss_prior: 0.0033849149476736784 loss_recons: 0.9548658132553101\n",
      "loss_prior: 0.0030464590527117252 loss_recons: 0.980595588684082\n",
      "loss_prior: 0.0024324865080416203 loss_recons: 0.8753212690353394\n",
      "loss_prior: 0.0022536844480782747 loss_recons: 0.7827792167663574\n",
      "loss_prior: 0.002089753746986389 loss_recons: 0.7639515399932861\n",
      "loss_prior: 0.0026256085839122534 loss_recons: 0.5651679635047913\n",
      "loss_prior: 0.0028187662828713655 loss_recons: 0.9534491896629333\n",
      "loss_prior: 0.0025887340307235718 loss_recons: 0.6828441023826599\n",
      "loss_prior: 0.0024067163467407227 loss_recons: 0.9148381948471069\n",
      "loss_prior: 0.0027743519749492407 loss_recons: 1.0386106967926025\n",
      "loss_prior: 0.0033740641083568335 loss_recons: 0.9256080389022827\n",
      "loss_prior: 0.005147507879883051 loss_recons: 1.0886064767837524\n",
      "loss_prior: 0.002665504813194275 loss_recons: 0.7678947448730469\n",
      "loss_prior: 0.002612596843391657 loss_recons: 0.991265594959259\n",
      "loss_prior: 0.0024529488291591406 loss_recons: 0.7553479671478271\n",
      "loss_prior: 0.0020364075899124146 loss_recons: 0.7781785130500793\n",
      "loss_prior: 0.004489630460739136 loss_recons: 0.9511139392852783\n",
      "loss_prior: 0.0022701621055603027 loss_recons: 0.7804308533668518\n",
      "loss_prior: 0.0032172442879527807 loss_recons: 0.956496000289917\n",
      "loss_prior: 0.0023434998001903296 loss_recons: 0.822554349899292\n",
      "loss_prior: 0.0029220611322671175 loss_recons: 0.6208688616752625\n",
      "loss_prior: 0.0020060092210769653 loss_recons: 0.8224340081214905\n",
      "loss_prior: 0.0022056312300264835 loss_recons: 0.9547540545463562\n",
      "loss_prior: 0.0022364079486578703 loss_recons: 0.6700619459152222\n",
      "loss_prior: 0.00198096944950521 loss_recons: 0.8507014513015747\n",
      "loss_prior: 0.0027313262689858675 loss_recons: 0.9385849833488464\n",
      "loss_prior: 0.0022068412508815527 loss_recons: 0.9987176656723022\n",
      "loss_prior: 0.0018483191961422563 loss_recons: 0.9708718061447144\n",
      "loss_prior: 0.0021172433625906706 loss_recons: 0.6342304348945618\n",
      "loss_prior: 0.0031603097449988127 loss_recons: 0.7705929279327393\n",
      "loss_prior: 0.0019884705543518066 loss_recons: 0.9824265241622925\n",
      "loss_prior: 0.002276003360748291 loss_recons: 1.1179918050765991\n",
      "loss_prior: 0.001884093857370317 loss_recons: 0.8264790177345276\n",
      "loss_prior: 0.0021994858980178833 loss_recons: 0.9601640701293945\n",
      "loss_prior: 0.002349132439121604 loss_recons: 0.8217425346374512\n",
      "loss_prior: 0.0017923206323757768 loss_recons: 0.8705753087997437\n",
      "loss_prior: 0.0025075108278542757 loss_recons: 0.876312792301178\n",
      "loss_prior: 0.0013863533968105912 loss_recons: 1.0330690145492554\n",
      "loss_prior: 0.0022305131424218416 loss_recons: 0.9348828196525574\n",
      "loss_prior: 0.002763897180557251 loss_recons: 1.3070915937423706\n",
      "loss_prior: 0.0021250874269753695 loss_recons: 0.9472427368164062\n",
      "loss_prior: 0.001984214875847101 loss_recons: 0.9203009605407715\n",
      "loss_prior: 0.0019796104170382023 loss_recons: 0.8711886405944824\n",
      "loss_prior: 0.001456999802030623 loss_recons: 0.8215880990028381\n",
      "loss_prior: 0.00218372349627316 loss_recons: 0.6663833260536194\n",
      "loss_prior: 0.001875758171081543 loss_recons: 1.0103310346603394\n",
      "loss_prior: 0.0019813894759863615 loss_recons: 0.8208395838737488\n",
      "loss_prior: 0.002322173211723566 loss_recons: 0.794245719909668\n",
      "loss_prior: 0.001424127840436995 loss_recons: 0.9408295750617981\n",
      "loss_prior: 0.0011878371005877852 loss_recons: 0.899260938167572\n",
      "loss_prior: 0.006699347402900457 loss_recons: 0.9165768027305603\n",
      "loss_prior: 0.0023447335697710514 loss_recons: 1.037013053894043\n",
      "loss_prior: 0.0026479840744286776 loss_recons: 1.0773634910583496\n",
      "loss_prior: 0.0018086492782458663 loss_recons: 0.7477787137031555\n",
      "loss_prior: 0.002345380140468478 loss_recons: 1.0469948053359985\n",
      "loss_prior: 0.0017228156793862581 loss_recons: 0.9453319907188416\n",
      "loss_prior: 0.001906594610773027 loss_recons: 0.9346655607223511\n",
      "loss_prior: 0.0028385163750499487 loss_recons: 0.8378081917762756\n",
      "loss_prior: 0.0030435502994805574 loss_recons: 0.9170262217521667\n",
      "loss_prior: 0.002299091313034296 loss_recons: 0.6753672361373901\n",
      "loss_prior: 0.002268067095428705 loss_recons: 0.7100094556808472\n",
      "loss_prior: 0.0016438186867162585 loss_recons: 0.7108054161071777\n",
      "loss_prior: 0.002151739550754428 loss_recons: 0.6423158645629883\n",
      "loss_prior: 0.0014763862127438188 loss_recons: 0.9449396729469299\n",
      "loss_prior: 0.0024015994276851416 loss_recons: 0.8897039294242859\n",
      "loss_prior: 0.0019950836431235075 loss_recons: 0.9353656768798828\n",
      "loss_prior: 0.001584663987159729 loss_recons: 1.0531549453735352\n",
      "loss_prior: 0.002003544708713889 loss_recons: 0.7449950575828552\n",
      "loss_prior: 0.0012741923565045 loss_recons: 0.7530872821807861\n",
      "loss_prior: 0.002325737616047263 loss_recons: 0.7440345883369446\n",
      "loss_prior: 0.0024987757205963135 loss_recons: 0.6966438293457031\n",
      "loss_prior: 0.0018439472187310457 loss_recons: 0.8045246005058289\n",
      "loss_prior: 0.0015874624950811267 loss_recons: 0.809691309928894\n",
      "loss_prior: 0.0014016658533364534 loss_recons: 0.9391121864318848\n",
      "loss_prior: 0.0016234725480899215 loss_recons: 1.1505186557769775\n",
      "loss_prior: 0.0018777818186208606 loss_recons: 1.0193116664886475\n",
      "loss_prior: 0.0014137268299236894 loss_recons: 0.791221559047699\n",
      "loss_prior: 0.0016165704000741243 loss_recons: 0.8371800184249878\n",
      "loss_prior: 0.0020821273792535067 loss_recons: 1.0395236015319824\n",
      "loss_prior: 0.0014588952763006091 loss_recons: 0.9626169800758362\n",
      "loss_prior: 0.0015994430286809802 loss_recons: 1.064788579940796\n",
      "loss_prior: 0.002577039645984769 loss_recons: 0.8918024301528931\n",
      "loss_prior: 0.0017915427451953292 loss_recons: 0.7707725167274475\n",
      "loss_prior: 0.002753275679424405 loss_recons: 1.1223766803741455\n",
      "loss_prior: 0.0015807151794433594 loss_recons: 0.9065962433815002\n",
      "loss_prior: 0.0012624353403225541 loss_recons: 0.8082079291343689\n",
      "loss_prior: 0.001998957945033908 loss_recons: 0.9553752541542053\n",
      "loss_prior: 0.0018393307691439986 loss_recons: 0.7850011587142944\n",
      "loss_prior: 0.0026535242795944214 loss_recons: 0.8401924967765808\n",
      "loss_prior: 0.004569306969642639 loss_recons: 0.6346171498298645\n",
      "loss_prior: 0.0019783617462962866 loss_recons: 1.087933897972107\n",
      "loss_prior: 0.0015884399181231856 loss_recons: 0.7161078453063965\n",
      "loss_prior: 0.0015391976339742541 loss_recons: 0.941202700138092\n",
      "loss_prior: 0.0023335875011980534 loss_recons: 0.8570152521133423\n",
      "loss_prior: 0.0015643120277673006 loss_recons: 0.955097496509552\n",
      "loss_prior: 0.0015040040016174316 loss_recons: 0.6627691984176636\n",
      "loss_prior: 0.0011423170799389482 loss_recons: 1.156008005142212\n",
      "loss_prior: 0.0015052556991577148 loss_recons: 0.782673716545105\n",
      "loss_prior: 0.0018790782196447253 loss_recons: 0.9064417481422424\n",
      "loss_prior: 0.001260241842828691 loss_recons: 0.804601788520813\n",
      "loss_prior: 0.0012913584941998124 loss_recons: 0.8952836990356445\n",
      "loss_prior: 0.0012580007314682007 loss_recons: 0.8658581972122192\n",
      "loss_prior: 0.0019380152225494385 loss_recons: 0.7401161789894104\n",
      "loss_prior: 0.0016065925592556596 loss_recons: 0.7954562902450562\n",
      "loss_prior: 0.002520883223041892 loss_recons: 0.7293708324432373\n",
      "loss_prior: 0.004065487068146467 loss_recons: 0.8142678737640381\n",
      "loss_prior: 0.0031244903802871704 loss_recons: 0.8834808468818665\n",
      "loss_prior: 0.001934763859026134 loss_recons: 1.0155746936798096\n",
      "loss_prior: 0.001455351710319519 loss_recons: 0.8534066677093506\n",
      "loss_prior: 0.006036305334419012 loss_recons: 0.947896420955658\n",
      "loss_prior: 0.0021826208103448153 loss_recons: 1.0158194303512573\n",
      "loss_prior: 0.0023926168214529753 loss_recons: 0.7953709363937378\n",
      "loss_prior: 0.0018363356357440352 loss_recons: 0.7804592847824097\n",
      "loss_prior: 0.0016633033519610763 loss_recons: 0.9089785218238831\n",
      "loss_prior: 0.00251502706669271 loss_recons: 0.9884777665138245\n",
      "loss_prior: 0.0017173439264297485 loss_recons: 0.8687514066696167\n",
      "loss_prior: 0.0019692094065248966 loss_recons: 0.6844651103019714\n",
      "loss_prior: 0.0027435333468019962 loss_recons: 1.1568868160247803\n",
      "loss_prior: 0.0017342895735055208 loss_recons: 0.9334962368011475\n",
      "loss_prior: 0.0024165064096450806 loss_recons: 0.9497601389884949\n",
      "loss_prior: 0.0029866041149944067 loss_recons: 0.912237823009491\n",
      "loss_prior: 0.0024937212001532316 loss_recons: 0.8977044224739075\n",
      "loss_prior: 0.0019870162941515446 loss_recons: 0.6887108087539673\n",
      "loss_prior: 0.0021357208024710417 loss_recons: 1.009433627128601\n",
      "loss_prior: 0.0029426782857626677 loss_recons: 0.8032707571983337\n",
      "loss_prior: 0.0023986937012523413 loss_recons: 0.827269434928894\n",
      "loss_prior: 0.0014598161214962602 loss_recons: 0.9195907711982727\n",
      "loss_prior: 0.0015436172252520919 loss_recons: 0.8675811886787415\n",
      "loss_prior: 0.001990377902984619 loss_recons: 1.015051007270813\n",
      "loss_prior: 0.0015529871452599764 loss_recons: 1.1931266784667969\n",
      "loss_prior: 0.002003270434215665 loss_recons: 1.0274269580841064\n",
      "loss_prior: 0.0022204339038580656 loss_recons: 0.9384464621543884\n",
      "loss_prior: 0.0014622688759118319 loss_recons: 0.9363866448402405\n",
      "loss_prior: 0.001492896699346602 loss_recons: 0.8010506629943848\n",
      "loss_prior: 0.001634690212085843 loss_recons: 0.8768467307090759\n",
      "loss_prior: 0.0044696154072880745 loss_recons: 0.8472875356674194\n",
      "loss_prior: 0.002128899097442627 loss_recons: 0.996665894985199\n",
      "loss_prior: 0.0016361803282052279 loss_recons: 0.8493242859840393\n",
      "loss_prior: 0.0016776472330093384 loss_recons: 0.8512069582939148\n",
      "loss_prior: 0.0013198376400396228 loss_recons: 1.0228383541107178\n",
      "loss_prior: 0.0016983210807666183 loss_recons: 0.6843082904815674\n",
      "loss_prior: 0.001492300652898848 loss_recons: 0.9671977758407593\n",
      "loss_prior: 0.0015489429933950305 loss_recons: 0.8450891375541687\n",
      "loss_prior: 0.001674845814704895 loss_recons: 0.9975364804267883\n",
      "loss_prior: 0.004704973194748163 loss_recons: 0.9001864194869995\n",
      "loss_prior: 0.0019265800947323442 loss_recons: 0.8718163371086121\n",
      "loss_prior: 0.002250492572784424 loss_recons: 0.8107810616493225\n",
      "loss_prior: 0.0023785026278346777 loss_recons: 0.9772886037826538\n",
      "loss_prior: 0.0024795772042125463 loss_recons: 0.9253337383270264\n",
      "loss_prior: 0.0011758477194234729 loss_recons: 0.9119901061058044\n",
      "loss_prior: 0.0014930934412404895 loss_recons: 0.8768981099128723\n",
      "loss_prior: 0.0013152093160897493 loss_recons: 0.7993278503417969\n",
      "loss_prior: 0.0017251670360565186 loss_recons: 0.7389832139015198\n",
      "loss_prior: 0.0013099134666845202 loss_recons: 0.8850377202033997\n",
      "loss_prior: 0.0015663504600524902 loss_recons: 0.8543476462364197\n",
      "loss_prior: 0.0014151394134387374 loss_recons: 0.8424586057662964\n",
      "loss_prior: 0.001903775380924344 loss_recons: 0.7346110939979553\n",
      "loss_prior: 0.0011806637048721313 loss_recons: 0.8642394542694092\n",
      "loss_prior: 0.0010697961552068591 loss_recons: 0.7847908735275269\n",
      "loss_prior: 0.0012990593677386642 loss_recons: 1.0075074434280396\n",
      "loss_prior: 0.001210650778375566 loss_recons: 0.7869701385498047\n",
      "loss_prior: 0.0038089097943156958 loss_recons: 0.6895152926445007\n",
      "loss_prior: 0.0014424205292016268 loss_recons: 0.6680202484130859\n",
      "loss_prior: 0.0015012174844741821 loss_recons: 0.9670238494873047\n",
      "loss_prior: 0.0012121200561523438 loss_recons: 0.9373242855072021\n",
      "loss_prior: 0.0014868855942040682 loss_recons: 0.9185428619384766\n",
      "loss_prior: 0.002033862518146634 loss_recons: 0.965873658657074\n",
      "loss_prior: 0.0011667072540149093 loss_recons: 0.9993051886558533\n",
      "loss_prior: 0.0017825275426730514 loss_recons: 0.7233896851539612\n",
      "loss_prior: 0.0016640395624563098 loss_recons: 0.7085608243942261\n",
      "loss_prior: 0.0013648540480062366 loss_recons: 0.6803914904594421\n",
      "loss_prior: 0.0021617114543914795 loss_recons: 0.9583922624588013\n",
      "loss_prior: 0.0012175232404842973 loss_recons: 0.8128736615180969\n",
      "loss_prior: 0.0015197902685031295 loss_recons: 0.8554348349571228\n",
      "loss_prior: 0.0012908995850011706 loss_recons: 0.7940187454223633\n",
      "loss_prior: 0.0012508213985711336 loss_recons: 0.9967911839485168\n",
      "loss_prior: 0.001423373818397522 loss_recons: 0.8868023157119751\n",
      "loss_prior: 0.001531147980131209 loss_recons: 1.0343562364578247\n",
      "loss_prior: 0.001127696014009416 loss_recons: 0.8273538947105408\n",
      "loss_prior: 0.0010582477552816272 loss_recons: 0.7647370100021362\n",
      "loss_prior: 0.0014299392933025956 loss_recons: 0.758249819278717\n",
      "loss_prior: 0.0035479129292070866 loss_recons: 0.7168701887130737\n",
      "loss_prior: 0.0013493358856067061 loss_recons: 0.7769813537597656\n",
      "loss_prior: 0.0011821180814877152 loss_recons: 1.0426661968231201\n",
      "loss_prior: 0.0010881125926971436 loss_recons: 0.8311288356781006\n",
      "loss_prior: 0.0019980042707175016 loss_recons: 0.8831679821014404\n",
      "loss_prior: 0.0019248336320742965 loss_recons: 0.8343110084533691\n",
      "loss_prior: 0.0012713968753814697 loss_recons: 0.6634498238563538\n",
      "loss_prior: 0.0010661780834197998 loss_recons: 0.9450214505195618\n",
      "loss_prior: 0.0022169591393321753 loss_recons: 1.003679871559143\n",
      "loss_prior: 0.0011733770370483398 loss_recons: 0.8558459877967834\n",
      "loss_prior: 0.001561173819936812 loss_recons: 0.9653762578964233\n",
      "loss_prior: 0.002155149122700095 loss_recons: 0.6135931015014648\n",
      "loss_prior: 0.0015375554794445634 loss_recons: 1.0199143886566162\n",
      "loss_prior: 0.0031452567782253027 loss_recons: 0.8880464434623718\n",
      "loss_prior: 0.0012206435203552246 loss_recons: 0.9716497659683228\n",
      "loss_prior: 0.0016453833086416125 loss_recons: 0.8576906323432922\n",
      "loss_prior: 0.0010473848087713122 loss_recons: 1.0149853229522705\n",
      "loss_prior: 0.0021217733155936003 loss_recons: 0.8467360138893127\n",
      "loss_prior: 0.0015214175218716264 loss_recons: 0.6092074513435364\n",
      "loss_prior: 0.001056545996107161 loss_recons: 1.0443024635314941\n",
      "loss_prior: 0.0015324325067922473 loss_recons: 0.8548477292060852\n",
      "loss_prior: 0.0011616498231887817 loss_recons: 0.8422152400016785\n",
      "loss_prior: 0.0016573965549468994 loss_recons: 0.9337704181671143\n",
      "loss_prior: 0.0012973040575161576 loss_recons: 0.8039400577545166\n",
      "loss_prior: 0.0016301096184179187 loss_recons: 0.9168538451194763\n",
      "loss_prior: 0.0010900795459747314 loss_recons: 0.7813128232955933\n",
      "loss_prior: 0.0010828226804733276 loss_recons: 0.8821813464164734\n",
      "loss_prior: 0.0013990879524499178 loss_recons: 0.8812383413314819\n",
      "loss_prior: 0.001297834562137723 loss_recons: 0.7959374785423279\n",
      "loss_prior: 0.0015274375909939408 loss_recons: 1.0226404666900635\n",
      "loss_prior: 0.0009448349592275918 loss_recons: 0.8469213843345642\n",
      "loss_prior: 0.001248720334842801 loss_recons: 0.5551596283912659\n",
      "loss_prior: 0.0016721546417102218 loss_recons: 0.8216447830200195\n",
      "loss_prior: 0.001681208610534668 loss_recons: 0.9213560223579407\n",
      "loss_prior: 0.0016239077085629106 loss_recons: 0.9969931840896606\n",
      "loss_prior: 0.0011962592834606767 loss_recons: 0.8068405985832214\n",
      "loss_prior: 0.0010127396089956164 loss_recons: 0.8905980587005615\n",
      "loss_prior: 0.0011827856069430709 loss_recons: 0.8667284846305847\n",
      "loss_prior: 0.0012130230898037553 loss_recons: 0.8593699932098389\n",
      "loss_prior: 0.0013417572481557727 loss_recons: 1.0487968921661377\n",
      "loss_prior: 0.0014743119245395064 loss_recons: 0.9204127192497253\n",
      "loss_prior: 0.001395258354023099 loss_recons: 0.7323616743087769\n",
      "loss_prior: 0.0011104614241048694 loss_recons: 0.9105743765830994\n",
      "loss_prior: 0.0010322123998776078 loss_recons: 0.8484212160110474\n",
      "loss_prior: 0.0014416903723031282 loss_recons: 0.8347114324569702\n",
      "loss_prior: 0.001294088433496654 loss_recons: 0.911748468875885\n",
      "loss_prior: 0.0017371654976159334 loss_recons: 0.9213132858276367\n",
      "loss_prior: 0.0012956112623214722 loss_recons: 0.7539787292480469\n",
      "loss_prior: 0.0010607570875436068 loss_recons: 0.8808779120445251\n",
      "loss_prior: 0.0014242500765249133 loss_recons: 1.0700860023498535\n",
      "loss_prior: 0.0011316090822219849 loss_recons: 0.8434409499168396\n",
      "loss_prior: 0.0012197286123409867 loss_recons: 0.8483927845954895\n",
      "loss_prior: 0.0013626456493511796 loss_recons: 0.9836113452911377\n",
      "loss_prior: 0.003128916025161743 loss_recons: 0.8818092346191406\n",
      "loss_prior: 0.0013314932584762573 loss_recons: 0.8116807341575623\n",
      "loss_prior: 0.0013183773262426257 loss_recons: 0.84519362449646\n",
      "loss_prior: 0.0014641255838796496 loss_recons: 0.963009774684906\n",
      "loss_prior: 0.0012175918091088533 loss_recons: 0.8981262445449829\n",
      "loss_prior: 0.001299142837524414 loss_recons: 1.177732229232788\n",
      "loss_prior: 0.0010986656416207552 loss_recons: 0.8827612996101379\n",
      "loss_prior: 0.0016948580741882324 loss_recons: 0.9353859424591064\n",
      "loss_prior: 0.0017346919048577547 loss_recons: 1.0604511499404907\n",
      "loss_prior: 0.0019372225506231189 loss_recons: 0.9519268274307251\n",
      "loss_prior: 0.0009756148210726678 loss_recons: 1.0583471059799194\n",
      "loss_prior: 0.0018631964921951294 loss_recons: 0.8917748928070068\n",
      "loss_prior: 0.0025403262116014957 loss_recons: 0.7938665747642517\n",
      "loss_prior: 0.0011825710535049438 loss_recons: 0.8813899159431458\n",
      "loss_prior: 0.001448816037736833 loss_recons: 0.8169973492622375\n",
      "loss_prior: 0.001528552151285112 loss_recons: 0.8779656887054443\n",
      "loss_prior: 0.0016677230596542358 loss_recons: 1.0386996269226074\n",
      "loss_prior: 0.0010775089031085372 loss_recons: 0.6381856799125671\n",
      "loss_prior: 0.0011730492115020752 loss_recons: 0.6463279724121094\n",
      "loss_prior: 0.0012369751930236816 loss_recons: 0.8683757185935974\n",
      "loss_prior: 0.0019437134033069015 loss_recons: 0.9611573815345764\n",
      "loss_prior: 0.0029106021393090487 loss_recons: 0.8291921615600586\n",
      "loss_prior: 0.0013981283409520984 loss_recons: 0.831731379032135\n",
      "loss_prior: 0.0008912593475542963 loss_recons: 0.874687910079956\n",
      "loss_prior: 0.0013626962900161743 loss_recons: 0.8190539479255676\n",
      "loss_prior: 0.0014070331817492843 loss_recons: 0.8427901864051819\n",
      "loss_prior: 0.0013665289152413607 loss_recons: 0.6683207750320435\n",
      "loss_prior: 0.0010894716251641512 loss_recons: 0.7959968447685242\n",
      "loss_prior: 0.0013962298398837447 loss_recons: 0.8799911737442017\n",
      "loss_prior: 0.0011056869989261031 loss_recons: 0.9565034508705139\n",
      "loss_prior: 0.0013771385420113802 loss_recons: 1.148391604423523\n",
      "loss_prior: 0.0021592676639556885 loss_recons: 1.0438894033432007\n",
      "loss_prior: 0.0023793817963451147 loss_recons: 0.8267712593078613\n",
      "loss_prior: 0.0014984190929681063 loss_recons: 0.8620792627334595\n",
      "loss_prior: 0.0011403829557821155 loss_recons: 0.7384665608406067\n",
      "loss_prior: 0.0013908147811889648 loss_recons: 0.8417677879333496\n",
      "loss_prior: 0.0023533254861831665 loss_recons: 0.7644733190536499\n",
      "loss_prior: 0.0015122175682336092 loss_recons: 0.9110386967658997\n",
      "loss_prior: 0.0014937997329980135 loss_recons: 0.8467504978179932\n",
      "loss_prior: 0.0011752427089959383 loss_recons: 0.9935620427131653\n",
      "loss_prior: 0.0013122111558914185 loss_recons: 0.7660633325576782\n",
      "loss_prior: 0.0014080405235290527 loss_recons: 0.8629385828971863\n",
      "loss_prior: 0.0009243279928341508 loss_recons: 1.0424749851226807\n",
      "loss_prior: 0.002198159694671631 loss_recons: 0.8702371716499329\n",
      "loss_prior: 0.0020262121688574553 loss_recons: 0.8832685947418213\n",
      "loss_prior: 0.001514822244644165 loss_recons: 1.0470730066299438\n",
      "loss_prior: 0.0011108368635177612 loss_recons: 0.8338607549667358\n",
      "loss_prior: 0.0015415340894833207 loss_recons: 0.811344563961029\n",
      "loss_prior: 0.0015835464000701904 loss_recons: 0.8992021083831787\n",
      "loss_prior: 0.0014029681915417314 loss_recons: 0.8068708181381226\n",
      "loss_prior: 0.0014783352380618453 loss_recons: 0.8827112317085266\n",
      "loss_prior: 0.0009799301624298096 loss_recons: 0.8335328102111816\n",
      "loss_prior: 0.002725002123042941 loss_recons: 0.7519266605377197\n",
      "loss_prior: 0.001341486000455916 loss_recons: 0.7864758968353271\n",
      "loss_prior: 0.0022256553638726473 loss_recons: 0.7781050205230713\n",
      "loss_prior: 0.0012714684708043933 loss_recons: 0.9022198915481567\n",
      "loss_prior: 0.0017129987245425582 loss_recons: 1.2129701375961304\n",
      "loss_prior: 0.001065927790477872 loss_recons: 0.7296826839447021\n",
      "loss_prior: 0.0012890994548797607 loss_recons: 0.9139270186424255\n",
      "loss_prior: 0.001435273909009993 loss_recons: 0.75921231508255\n",
      "loss_prior: 0.0015527516370639205 loss_recons: 0.8414775729179382\n",
      "loss_prior: 0.0018632591236382723 loss_recons: 0.8640184998512268\n",
      "loss_prior: 0.0015058100689202547 loss_recons: 0.8959653973579407\n",
      "loss_prior: 0.001544398139230907 loss_recons: 0.8460633158683777\n",
      "loss_prior: 0.0012903064489364624 loss_recons: 0.9337157607078552\n",
      "loss_prior: 0.0014941871631890535 loss_recons: 0.9443069696426392\n",
      "loss_prior: 0.0010166525607928634 loss_recons: 0.8986456990242004\n",
      "loss_prior: 0.0011366367107257247 loss_recons: 0.9958341717720032\n",
      "loss_prior: 0.0011887819273397326 loss_recons: 0.5721063613891602\n",
      "loss_prior: 0.0011845410335808992 loss_recons: 0.9765952229499817\n",
      "loss_prior: 0.0015877009136602283 loss_recons: 0.7501085996627808\n",
      "loss_prior: 0.0018921286100521684 loss_recons: 0.7534230947494507\n",
      "loss_prior: 0.0009649991989135742 loss_recons: 0.7717829942703247\n",
      "loss_prior: 0.0012767970329150558 loss_recons: 0.7000955939292908\n",
      "loss_prior: 0.0011043250560760498 loss_recons: 0.828015923500061\n",
      "loss_prior: 0.0013166069984436035 loss_recons: 0.9251337647438049\n",
      "loss_prior: 0.0008663773769512773 loss_recons: 0.9267593026161194\n",
      "loss_prior: 0.0026206851471215487 loss_recons: 0.6681710481643677\n",
      "loss_prior: 0.0010792583925649524 loss_recons: 0.7835478782653809\n",
      "loss_prior: 0.0011935144430026412 loss_recons: 0.9420797824859619\n",
      "loss_prior: 0.00148345238994807 loss_recons: 0.8516929745674133\n",
      "loss_prior: 0.0010728597408160567 loss_recons: 1.0361779928207397\n",
      "loss_prior: 0.0012582809431478381 loss_recons: 0.6421419382095337\n",
      "loss_prior: 0.0010980963706970215 loss_recons: 1.1349754333496094\n",
      "loss_prior: 0.0009291142341680825 loss_recons: 0.8068080544471741\n",
      "loss_prior: 0.0011456281645223498 loss_recons: 0.8673983216285706\n",
      "loss_prior: 0.0011482745176181197 loss_recons: 0.9817429184913635\n",
      "loss_prior: 0.0010778576834127307 loss_recons: 0.7981683611869812\n",
      "loss_prior: 0.003701084991917014 loss_recons: 0.6555137038230896\n",
      "loss_prior: 0.0015218675835058093 loss_recons: 0.8133431673049927\n",
      "loss_prior: 0.0012442589504644275 loss_recons: 0.7947626113891602\n",
      "loss_prior: 0.0009760588291101158 loss_recons: 0.7286924719810486\n",
      "loss_prior: 0.001524078892543912 loss_recons: 0.9136434197425842\n",
      "loss_prior: 0.014864671044051647 loss_recons: 0.9469220042228699\n",
      "loss_prior: 0.0024546801578253508 loss_recons: 0.9854451417922974\n",
      "loss_prior: 0.0016590416198596358 loss_recons: 0.6956577897071838\n",
      "loss_prior: 0.0016972244484350085 loss_recons: 0.9271379709243774\n",
      "loss_prior: 0.0010799377923831344 loss_recons: 0.6368441581726074\n",
      "loss_prior: 0.001086309552192688 loss_recons: 0.7619819641113281\n",
      "loss_prior: 0.0016194850904867053 loss_recons: 1.0480657815933228\n",
      "loss_prior: 0.001640859292820096 loss_recons: 1.0076851844787598\n",
      "loss_prior: 0.0010519534116610885 loss_recons: 0.9227911233901978\n",
      "loss_prior: 0.0015931576490402222 loss_recons: 0.785216748714447\n",
      "loss_prior: 0.001875141286291182 loss_recons: 0.819787859916687\n",
      "loss_prior: 0.0018921286100521684 loss_recons: 0.950151264667511\n",
      "loss_prior: 0.0014759928453713655 loss_recons: 0.9786500930786133\n",
      "loss_prior: 0.0017110168701037765 loss_recons: 0.8269385099411011\n",
      "loss_prior: 0.002412945032119751 loss_recons: 0.9076145887374878\n",
      "loss_prior: 0.0018119246233254671 loss_recons: 0.8971003293991089\n",
      "loss_prior: 0.002639543963596225 loss_recons: 0.8121914863586426\n",
      "loss_prior: 0.0012020021677017212 loss_recons: 0.8268496990203857\n",
      "loss_prior: 0.00122012197971344 loss_recons: 1.1278175115585327\n",
      "loss_prior: 0.0013731897342950106 loss_recons: 1.0001091957092285\n",
      "loss_prior: 0.003245288273319602 loss_recons: 0.9711564183235168\n",
      "loss_prior: 0.00175534188747406 loss_recons: 0.8429888486862183\n",
      "loss_prior: 0.001942220376804471 loss_recons: 0.8012350797653198\n",
      "loss_prior: 0.0017783790826797485 loss_recons: 0.7041833400726318\n",
      "loss_prior: 0.0023664713371545076 loss_recons: 0.7144817113876343\n",
      "loss_prior: 0.0012063294416293502 loss_recons: 0.9542307257652283\n",
      "loss_prior: 0.0012331545585766435 loss_recons: 0.83625727891922\n",
      "loss_prior: 0.0015043169260025024 loss_recons: 0.8920910954475403\n",
      "loss_prior: 0.0017816246254369617 loss_recons: 0.8774179816246033\n",
      "loss_prior: 0.001383149647153914 loss_recons: 0.8854307532310486\n",
      "loss_prior: 0.0022266507148742676 loss_recons: 0.804295539855957\n",
      "loss_prior: 0.001268708729185164 loss_recons: 0.8762459754943848\n",
      "loss_prior: 0.0015772850019857287 loss_recons: 0.8946298956871033\n",
      "loss_prior: 0.0011892557376995683 loss_recons: 0.7836199998855591\n",
      "loss_prior: 0.0009695649496279657 loss_recons: 0.9890388250350952\n",
      "loss_prior: 0.0013877988094463944 loss_recons: 1.017072081565857\n",
      "loss_prior: 0.0009763300768099725 loss_recons: 0.8406312465667725\n",
      "loss_prior: 0.001761788153089583 loss_recons: 0.8813199400901794\n",
      "loss_prior: 0.0008704275242052972 loss_recons: 0.8459102511405945\n",
      "loss_prior: 0.0009186834213323891 loss_recons: 0.8695637583732605\n",
      "loss_prior: 0.0009633511654101312 loss_recons: 1.0943819284439087\n",
      "loss_prior: 0.0010494053130969405 loss_recons: 0.7342926859855652\n",
      "loss_prior: 0.002445018384605646 loss_recons: 0.8747687935829163\n",
      "loss_prior: 0.0012949228985235095 loss_recons: 0.8476502299308777\n",
      "loss_prior: 0.001454451703466475 loss_recons: 0.6704772710800171\n",
      "loss_prior: 0.0008536637178622186 loss_recons: 0.7785251140594482\n",
      "loss_prior: 0.0008355826139450073 loss_recons: 0.9737262725830078\n",
      "loss_prior: 0.0010948599083349109 loss_recons: 0.789117157459259\n",
      "loss_prior: 0.0010983735555782914 loss_recons: 0.8949816226959229\n",
      "loss_prior: 0.0016267627943307161 loss_recons: 0.9550641179084778\n",
      "loss_prior: 0.0010840296745300293 loss_recons: 0.8204339742660522\n",
      "loss_prior: 0.0011346638202667236 loss_recons: 0.7986249923706055\n",
      "loss_prior: 0.0016237556701526046 loss_recons: 0.8640856742858887\n",
      "loss_prior: 0.0013709486229345202 loss_recons: 0.801067054271698\n",
      "loss_prior: 0.0007366359350271523 loss_recons: 0.9544737935066223\n",
      "loss_prior: 0.0009481728193350136 loss_recons: 0.9022084474563599\n",
      "loss_prior: 0.0007997244829311967 loss_recons: 0.9018216133117676\n",
      "loss_prior: 0.001040235161781311 loss_recons: 0.9073557257652283\n",
      "loss_prior: 0.030328307300806046 loss_recons: 0.9367275238037109\n",
      "loss_prior: 0.001883152173832059 loss_recons: 0.9468199610710144\n",
      "loss_prior: 0.0025371015071868896 loss_recons: 0.9942068457603455\n",
      "loss_prior: 0.0014093905920162797 loss_recons: 0.8345802426338196\n",
      "loss_prior: 0.0018697679042816162 loss_recons: 0.7850667834281921\n",
      "loss_prior: 0.0022091090213507414 loss_recons: 0.6968247294425964\n",
      "loss_prior: 0.0021817355882376432 loss_recons: 0.6967659592628479\n",
      "loss_prior: 0.0023613811936229467 loss_recons: 0.7337890267372131\n",
      "loss_prior: 0.0015691459411755204 loss_recons: 0.8565316796302795\n",
      "loss_prior: 0.0014519274700433016 loss_recons: 0.9176856279373169\n",
      "loss_prior: 0.011385882273316383 loss_recons: 0.9530287384986877\n",
      "loss_prior: 0.0023120343685150146 loss_recons: 0.7455915808677673\n",
      "loss_prior: 0.002412274479866028 loss_recons: 0.7549127340316772\n",
      "loss_prior: 0.0018014311790466309 loss_recons: 0.6917075514793396\n",
      "loss_prior: 0.0035219669807702303 loss_recons: 0.8922375440597534\n",
      "loss_prior: 0.002663177205249667 loss_recons: 0.7676908373832703\n",
      "loss_prior: 0.003393274499103427 loss_recons: 0.781610369682312\n",
      "loss_prior: 0.0026065409183502197 loss_recons: 0.9655472636222839\n",
      "loss_prior: 0.0016534716123715043 loss_recons: 0.8288877606391907\n",
      "loss_prior: 0.0022981674410402775 loss_recons: 0.8153669238090515\n",
      "loss_prior: 0.0017273009289056063 loss_recons: 0.999183177947998\n",
      "loss_prior: 0.00893857516348362 loss_recons: 0.9127044677734375\n",
      "loss_prior: 0.007551288697868586 loss_recons: 0.8571635484695435\n",
      "loss_prior: 0.002774953842163086 loss_recons: 0.8170197606086731\n",
      "loss_prior: 0.004716625902801752 loss_recons: 0.7571518421173096\n",
      "loss_prior: 0.0028256834484636784 loss_recons: 0.8559238314628601\n",
      "loss_prior: 0.00145635602530092 loss_recons: 0.8385521173477173\n",
      "loss_prior: 0.002408680273219943 loss_recons: 1.0544441938400269\n",
      "loss_prior: 0.0033932984806597233 loss_recons: 0.8798694014549255\n",
      "loss_prior: 0.0012897789711132646 loss_recons: 0.789361298084259\n",
      "loss_prior: 0.005083632655441761 loss_recons: 0.7802904844284058\n",
      "loss_prior: 0.0028696865774691105 loss_recons: 1.0026295185089111\n",
      "loss_prior: 0.002409842563793063 loss_recons: 0.8525270223617554\n",
      "loss_prior: 0.002308631082996726 loss_recons: 0.996463418006897\n",
      "loss_prior: 0.0026561529375612736 loss_recons: 0.9349861741065979\n",
      "loss_prior: 0.0018507272470742464 loss_recons: 0.8909898400306702\n",
      "loss_prior: 0.008975351229310036 loss_recons: 0.7565435171127319\n",
      "loss_prior: 0.00274619460105896 loss_recons: 0.7761452794075012\n",
      "loss_prior: 0.0022335441317409277 loss_recons: 0.948743999004364\n",
      "loss_prior: 0.0017283976776525378 loss_recons: 0.9526776671409607\n",
      "loss_prior: 0.0018316000932827592 loss_recons: 1.0516585111618042\n",
      "loss_prior: 0.003566983388736844 loss_recons: 0.8887649178504944\n",
      "loss_prior: 0.0013571948511525989 loss_recons: 0.883183479309082\n",
      "loss_prior: 0.001993852900341153 loss_recons: 0.9792661666870117\n",
      "loss_prior: 0.001508438610471785 loss_recons: 0.9714639186859131\n",
      "loss_prior: 0.001972407102584839 loss_recons: 0.9441173076629639\n",
      "loss_prior: 0.002122411271557212 loss_recons: 0.7656339406967163\n",
      "loss_prior: 0.0015074163675308228 loss_recons: 0.9172282218933105\n",
      "loss_prior: 0.0015245437389239669 loss_recons: 0.716011643409729\n",
      "loss_prior: 0.0014511526096612215 loss_recons: 0.8121759295463562\n",
      "loss_prior: 0.0015088915824890137 loss_recons: 0.8373494148254395\n",
      "loss_prior: 0.0017096847295761108 loss_recons: 0.8868361115455627\n",
      "loss_prior: 0.001096895313821733 loss_recons: 0.8824291825294495\n",
      "loss_prior: 0.0013866395456716418 loss_recons: 0.9731445908546448\n",
      "loss_prior: 0.0013226837618276477 loss_recons: 0.9041746854782104\n",
      "loss_prior: 0.001187333487905562 loss_recons: 0.621031641960144\n",
      "loss_prior: 0.0012586296070367098 loss_recons: 0.8891347050666809\n",
      "loss_prior: 0.001998215913772583 loss_recons: 0.7443573474884033\n",
      "loss_prior: 0.0025245249271392822 loss_recons: 0.9917343854904175\n",
      "loss_prior: 0.001820150064304471 loss_recons: 0.9161026477813721\n",
      "loss_prior: 0.0016227960586547852 loss_recons: 0.9283977746963501\n",
      "loss_prior: 0.0015958130825310946 loss_recons: 0.7565016746520996\n",
      "loss_prior: 0.0014472067123278975 loss_recons: 0.8379529714584351\n",
      "loss_prior: 0.0010440171463415027 loss_recons: 0.7377742528915405\n",
      "loss_prior: 0.0013056517345830798 loss_recons: 0.8478858470916748\n",
      "loss_prior: 0.0012590527767315507 loss_recons: 0.8912252187728882\n",
      "loss_prior: 0.001024803495965898 loss_recons: 1.0271750688552856\n",
      "loss_prior: 0.0012226880062371492 loss_recons: 0.7592162489891052\n",
      "loss_prior: 0.0017129213083535433 loss_recons: 0.7061396241188049\n",
      "loss_prior: 0.001272314810194075 loss_recons: 0.7865265607833862\n",
      "loss_prior: 0.002301183296367526 loss_recons: 0.9420556426048279\n",
      "loss_prior: 0.0008948624017648399 loss_recons: 0.8409515023231506\n",
      "loss_prior: 0.0009857416152954102 loss_recons: 0.875840425491333\n",
      "loss_prior: 0.0011474043130874634 loss_recons: 0.9699840545654297\n",
      "loss_prior: 0.0012793511850759387 loss_recons: 0.6740070581436157\n",
      "loss_prior: 0.001969373319298029 loss_recons: 0.8136770725250244\n",
      "loss_prior: 0.0021523446775972843 loss_recons: 0.8976401090621948\n",
      "loss_prior: 0.0012801856501027942 loss_recons: 0.6449664831161499\n",
      "loss_prior: 0.0010634094942361116 loss_recons: 0.957194447517395\n",
      "loss_prior: 0.0029284029733389616 loss_recons: 0.8161080479621887\n",
      "loss_prior: 0.0011572748189792037 loss_recons: 0.6602535843849182\n",
      "loss_prior: 0.0010637551313266158 loss_recons: 0.8202031254768372\n",
      "loss_prior: 0.0014333516592159867 loss_recons: 0.8909776210784912\n",
      "loss_prior: 0.0012500673765316606 loss_recons: 0.7094060778617859\n",
      "loss_prior: 0.0011344999074935913 loss_recons: 0.783206582069397\n",
      "loss_prior: 0.001468464732170105 loss_recons: 0.851469874382019\n",
      "loss_prior: 0.0009928137296810746 loss_recons: 0.7594089508056641\n",
      "loss_prior: 0.0012732952600345016 loss_recons: 0.9722548127174377\n",
      "loss_prior: 0.0007627666345797479 loss_recons: 0.733372688293457\n",
      "loss_prior: 0.0024948955979198217 loss_recons: 0.9464848637580872\n",
      "loss_prior: 0.0009905785555019975 loss_recons: 0.79721999168396\n",
      "loss_prior: 0.0010000824695453048 loss_recons: 0.9171979427337646\n",
      "loss_prior: 0.0009326756116934121 loss_recons: 0.8260699510574341\n",
      "loss_prior: 0.0018675149185582995 loss_recons: 0.7899861931800842\n",
      "loss_prior: 0.0012626469833776355 loss_recons: 0.9157571196556091\n",
      "loss_prior: 0.000971058034338057 loss_recons: 0.8671264052391052\n",
      "loss_prior: 0.0009377807728014886 loss_recons: 0.8554404973983765\n",
      "loss_prior: 0.0010206670267507434 loss_recons: 0.8322762250900269\n",
      "loss_prior: 0.0014184266328811646 loss_recons: 0.8479532599449158\n",
      "loss_prior: 0.0020387829281389713 loss_recons: 0.8530930876731873\n",
      "loss_prior: 0.0012254089815542102 loss_recons: 0.6171908974647522\n",
      "loss_prior: 0.0010227382881566882 loss_recons: 0.7915353775024414\n",
      "loss_prior: 0.000871315598487854 loss_recons: 0.9242426156997681\n",
      "loss_prior: 0.0009668737766332924 loss_recons: 0.6907334327697754\n",
      "loss_prior: 0.0007634818903170526 loss_recons: 0.9471375942230225\n",
      "loss_prior: 0.0010536998743191361 loss_recons: 1.0815331935882568\n",
      "loss_prior: 0.0007350295782089233 loss_recons: 0.8214285969734192\n",
      "loss_prior: 0.0008882075781002641 loss_recons: 0.6714605689048767\n",
      "loss_prior: 0.0007319480064325035 loss_recons: 0.7829856872558594\n",
      "loss_prior: 0.0011236518621444702 loss_recons: 0.8811809420585632\n",
      "loss_prior: 0.0007897377363406122 loss_recons: 0.8870301246643066\n",
      "loss_prior: 0.00158005952835083 loss_recons: 0.907039225101471\n",
      "loss_prior: 0.0012376457452774048 loss_recons: 0.8873139023780823\n",
      "loss_prior: 0.0011783033842220902 loss_recons: 0.8825398683547974\n",
      "loss_prior: 0.0009133756393566728 loss_recons: 0.9009639024734497\n",
      "loss_prior: 0.0009653061861172318 loss_recons: 0.8067124485969543\n",
      "loss_prior: 0.0007308304193429649 loss_recons: 0.9366114139556885\n",
      "loss_prior: 0.0009963751072064042 loss_recons: 0.9876841306686401\n",
      "loss_prior: 0.0008084088913165033 loss_recons: 0.8651248216629028\n",
      "loss_prior: 0.0008722454658709466 loss_recons: 0.8108072280883789\n",
      "loss_prior: 0.0008117675897665322 loss_recons: 0.7255819439888\n",
      "loss_prior: 0.0024920820724219084 loss_recons: 1.0814459323883057\n",
      "loss_prior: 0.0008480638498440385 loss_recons: 0.9322530627250671\n",
      "loss_prior: 0.0008372932788915932 loss_recons: 1.1240572929382324\n",
      "loss_prior: 0.0010831415420398116 loss_recons: 0.8250781297683716\n",
      "loss_prior: 0.0007867902750149369 loss_recons: 0.834185004234314\n",
      "loss_prior: 0.0009353041532449424 loss_recons: 0.8794797658920288\n",
      "loss_prior: 0.002590090036392212 loss_recons: 0.8273318409919739\n",
      "loss_prior: 0.001208311296068132 loss_recons: 0.8705030679702759\n",
      "loss_prior: 0.0011062592966482043 loss_recons: 0.9582833647727966\n",
      "loss_prior: 0.0006694764015264809 loss_recons: 0.7271751761436462\n",
      "loss_prior: 0.000874230288900435 loss_recons: 0.8248231410980225\n",
      "loss_prior: 0.0011772364377975464 loss_recons: 0.955951452255249\n",
      "loss_prior: 0.00098029978107661 loss_recons: 0.9462073445320129\n",
      "loss_prior: 0.0012067168718203902 loss_recons: 0.907243013381958\n",
      "loss_prior: 0.0010074198944494128 loss_recons: 0.9217398166656494\n",
      "loss_prior: 0.0008154183742590249 loss_recons: 0.7701430320739746\n",
      "loss_prior: 0.0010034292936325073 loss_recons: 1.0453803539276123\n",
      "loss_prior: 0.0012685864930972457 loss_recons: 0.9914994835853577\n",
      "loss_prior: 0.0009286612621508539 loss_recons: 0.8585906028747559\n",
      "loss_prior: 0.0015955448616296053 loss_recons: 1.0262560844421387\n",
      "loss_prior: 0.0008146703476086259 loss_recons: 0.7182155251502991\n",
      "loss_prior: 0.001026797341182828 loss_recons: 0.8086966276168823\n",
      "loss_prior: 0.0006750136963091791 loss_recons: 0.7126523852348328\n",
      "loss_prior: 0.0011142522562295198 loss_recons: 0.7928902506828308\n",
      "loss_prior: 0.0012227327097207308 loss_recons: 0.7906696796417236\n",
      "loss_prior: 0.000780192029196769 loss_recons: 1.0363956689834595\n",
      "loss_prior: 0.0007933527231216431 loss_recons: 0.9070322513580322\n",
      "loss_prior: 0.001838260912336409 loss_recons: 0.7327426671981812\n",
      "loss_prior: 0.0010912477737292647 loss_recons: 0.7914344668388367\n",
      "loss_prior: 0.0009104758501052856 loss_recons: 0.9301286339759827\n",
      "loss_prior: 0.0009596377494744956 loss_recons: 0.8343846797943115\n",
      "loss_prior: 0.0008662432665005326 loss_recons: 0.8820337057113647\n",
      "loss_prior: 0.0006707489374093711 loss_recons: 0.9824223518371582\n",
      "loss_prior: 0.0015206426614895463 loss_recons: 0.7242964506149292\n",
      "loss_prior: 0.0015343755949288607 loss_recons: 0.8797348737716675\n",
      "loss_prior: 0.0009246081463061273 loss_recons: 0.7819505929946899\n",
      "loss_prior: 0.000981768942438066 loss_recons: 0.8958243131637573\n",
      "loss_prior: 0.002021339489147067 loss_recons: 0.8653118014335632\n",
      "loss_prior: 0.0008465319988317788 loss_recons: 0.8530170321464539\n",
      "loss_prior: 0.0008740603807382286 loss_recons: 0.7602893710136414\n",
      "loss_prior: 0.0007320881122723222 loss_recons: 0.9191176891326904\n",
      "loss_prior: 0.0006888866773806512 loss_recons: 0.8877596259117126\n",
      "loss_prior: 0.0015291005838662386 loss_recons: 0.7559601068496704\n",
      "loss_prior: 0.000758051872253418 loss_recons: 0.7735016345977783\n",
      "loss_prior: 0.0014733255375176668 loss_recons: 0.8327569961547852\n",
      "loss_prior: 0.001241320394910872 loss_recons: 1.106149435043335\n",
      "loss_prior: 0.000604203378316015 loss_recons: 0.8635457158088684\n",
      "loss_prior: 0.0006425887695513666 loss_recons: 1.0409424304962158\n",
      "loss_prior: 0.0008648872608318925 loss_recons: 0.9590988159179688\n",
      "loss_prior: 0.0007867366075515747 loss_recons: 0.9332998394966125\n",
      "loss_prior: 0.0020624399185180664 loss_recons: 0.7746682167053223\n",
      "loss_prior: 0.0011323541402816772 loss_recons: 0.8452962040901184\n",
      "loss_prior: 0.0008409559959545732 loss_recons: 0.8428177833557129\n",
      "loss_prior: 0.0007987082353793085 loss_recons: 0.6531826853752136\n",
      "loss_prior: 0.0007121950620785356 loss_recons: 0.844460666179657\n",
      "loss_prior: 0.000937473785597831 loss_recons: 0.9066011905670166\n",
      "loss_prior: 0.0015679687494412065 loss_recons: 0.9372298717498779\n",
      "loss_prior: 0.0008263736963272095 loss_recons: 0.8421258330345154\n",
      "loss_prior: 0.0011353910667821765 loss_recons: 0.7666125297546387\n",
      "loss_prior: 0.0009132921695709229 loss_recons: 0.9518001675605774\n",
      "loss_prior: 0.0007537722704000771 loss_recons: 0.8404677510261536\n",
      "loss_prior: 0.0007565468549728394 loss_recons: 0.7019110321998596\n",
      "loss_prior: 0.0007099122158251703 loss_recons: 0.6962692737579346\n",
      "loss_prior: 0.0006123990169726312 loss_recons: 0.9308404326438904\n",
      "loss_prior: 0.0006880551809445024 loss_recons: 1.032569169998169\n",
      "loss_prior: 0.001137810992076993 loss_recons: 1.0037721395492554\n",
      "loss_prior: 0.0009824096923694015 loss_recons: 0.9547097682952881\n",
      "loss_prior: 0.0015748441219329834 loss_recons: 0.9106683135032654\n",
      "loss_prior: 0.0009049355867318809 loss_recons: 0.90376877784729\n",
      "loss_prior: 0.000830641423817724 loss_recons: 0.7484645843505859\n",
      "loss_prior: 0.0007655590889044106 loss_recons: 0.6965402364730835\n",
      "loss_prior: 0.0009954512352123857 loss_recons: 0.9619582891464233\n",
      "loss_prior: 0.0008358776685781777 loss_recons: 0.6468943357467651\n",
      "loss_prior: 0.0009434640523977578 loss_recons: 0.9438390731811523\n",
      "loss_prior: 0.0005801439401693642 loss_recons: 0.9606500864028931\n",
      "loss_prior: 0.0016918182373046875 loss_recons: 0.9270648956298828\n",
      "loss_prior: 0.0009172946447506547 loss_recons: 0.8810956478118896\n",
      "loss_prior: 0.0008955001831054688 loss_recons: 0.8988303542137146\n",
      "loss_prior: 0.0006030440563336015 loss_recons: 0.7509375810623169\n",
      "loss_prior: 0.0008032172918319702 loss_recons: 0.8460583090782166\n",
      "loss_prior: 0.0007614672067575157 loss_recons: 0.6122129559516907\n",
      "loss_prior: 0.0010095358593389392 loss_recons: 0.7414038181304932\n",
      "loss_prior: 0.0010152965551242232 loss_recons: 0.75978022813797\n",
      "loss_prior: 0.000872409378644079 loss_recons: 0.8966671824455261\n",
      "loss_prior: 0.0012049078941345215 loss_recons: 0.9696062207221985\n",
      "loss_prior: 0.0007831394905224442 loss_recons: 0.9507813453674316\n",
      "loss_prior: 0.000754493463318795 loss_recons: 0.9032652974128723\n",
      "loss_prior: 0.0005525261512957513 loss_recons: 1.1730165481567383\n",
      "loss_prior: 0.0012372881174087524 loss_recons: 0.9029836058616638\n",
      "loss_prior: 0.0012320041423663497 loss_recons: 0.9118643999099731\n",
      "loss_prior: 0.0007184624555520713 loss_recons: 0.8132407665252686\n",
      "loss_prior: 0.0007328331703320146 loss_recons: 0.7524153590202332\n",
      "loss_prior: 0.0006356119993142784 loss_recons: 0.7325831055641174\n",
      "loss_prior: 0.0006000042194500566 loss_recons: 0.9448729753494263\n",
      "loss_prior: 0.0007434100261889398 loss_recons: 0.7251705527305603\n",
      "loss_prior: 0.0009209513664245605 loss_recons: 0.8447677493095398\n",
      "loss_prior: 0.0013423115015029907 loss_recons: 0.7518528699874878\n",
      "loss_prior: 0.0008236885187216103 loss_recons: 0.8903228640556335\n",
      "loss_prior: 0.0008736133459024131 loss_recons: 1.0384764671325684\n",
      "loss_prior: 0.0009585052612237632 loss_recons: 0.8380164504051208\n",
      "loss_prior: 0.0008165925974026322 loss_recons: 1.0897812843322754\n",
      "loss_prior: 0.0007631838670931756 loss_recons: 1.151598334312439\n",
      "loss_prior: 0.0007914602756500244 loss_recons: 1.041436791419983\n",
      "loss_prior: 0.0008614897960796952 loss_recons: 0.7616094350814819\n",
      "loss_prior: 0.0007008523098193109 loss_recons: 0.9320421814918518\n",
      "loss_prior: 0.0008725643274374306 loss_recons: 0.8744146823883057\n",
      "loss_prior: 0.0011804223759099841 loss_recons: 0.7299236059188843\n",
      "loss_prior: 0.0014844447141513228 loss_recons: 0.8809337615966797\n",
      "loss_prior: 0.0006958484882488847 loss_recons: 0.8901249170303345\n",
      "loss_prior: 0.0008885383722372353 loss_recons: 0.7978287935256958\n",
      "loss_prior: 0.0005827784771099687 loss_recons: 0.724780261516571\n",
      "loss_prior: 0.0007592499605379999 loss_recons: 1.1012321710586548\n",
      "loss_prior: 0.0007748842472210526 loss_recons: 0.9974268674850464\n",
      "loss_prior: 0.0007115096086636186 loss_recons: 1.0719505548477173\n",
      "loss_prior: 0.0006354600191116333 loss_recons: 0.8414347171783447\n",
      "loss_prior: 0.0004871636629104614 loss_recons: 0.8476561307907104\n",
      "loss_prior: 0.0007691711070947349 loss_recons: 1.0660054683685303\n",
      "loss_prior: 0.0006246447446756065 loss_recons: 0.9361647367477417\n",
      "loss_prior: 0.0006894111866131425 loss_recons: 0.7718554735183716\n",
      "loss_prior: 0.0009677588823251426 loss_recons: 0.9120146036148071\n",
      "loss_prior: 0.0014568924671038985 loss_recons: 0.8492263555526733\n",
      "loss_prior: 0.0009121120092459023 loss_recons: 1.0006816387176514\n",
      "loss_prior: 0.0006285905838012695 loss_recons: 0.8280970454216003\n",
      "loss_prior: 0.0006843387964181602 loss_recons: 0.8961171507835388\n",
      "loss_prior: 0.0007712662336416543 loss_recons: 0.8575340509414673\n",
      "loss_prior: 0.0006505966302938759 loss_recons: 0.955900251865387\n",
      "loss_prior: 0.0006637453916482627 loss_recons: 0.6989201903343201\n",
      "loss_prior: 0.0007393389823846519 loss_recons: 1.0203570127487183\n",
      "loss_prior: 0.0009054035181179643 loss_recons: 0.8711352944374084\n",
      "loss_prior: 0.0008050978067331016 loss_recons: 0.9463244676589966\n",
      "loss_prior: 0.0005333691951818764 loss_recons: 0.8356974720954895\n",
      "loss_prior: 0.000660738383885473 loss_recons: 0.7492203712463379\n",
      "loss_prior: 0.001151913427747786 loss_recons: 0.8671066761016846\n",
      "loss_prior: 0.0011186779011040926 loss_recons: 0.7481263279914856\n",
      "loss_prior: 0.0006990552064962685 loss_recons: 0.9165257215499878\n",
      "loss_prior: 0.0005741298082284629 loss_recons: 1.079971432685852\n",
      "loss_prior: 0.0009097635629586875 loss_recons: 0.7632965445518494\n",
      "loss_prior: 0.0005930691841058433 loss_recons: 0.8951232433319092\n",
      "loss_prior: 0.0008456766954623163 loss_recons: 0.8021371364593506\n",
      "loss_prior: 0.0005548000335693359 loss_recons: 0.6822808384895325\n",
      "loss_prior: 0.0007334351539611816 loss_recons: 0.7481539249420166\n",
      "loss_prior: 0.0007793545955792069 loss_recons: 1.1573023796081543\n",
      "loss_prior: 0.0009504228946752846 loss_recons: 0.9950132966041565\n",
      "loss_prior: 0.0007825762149877846 loss_recons: 0.9683013558387756\n",
      "loss_prior: 0.0006792456260882318 loss_recons: 1.0127445459365845\n",
      "loss_prior: 0.0006889283540658653 loss_recons: 0.9473139643669128\n",
      "loss_prior: 0.0009643405792303383 loss_recons: 0.9791657328605652\n",
      "loss_prior: 0.0007801800966262817 loss_recons: 0.7798351049423218\n",
      "loss_prior: 0.00073705316754058 loss_recons: 1.0514373779296875\n",
      "loss_prior: 0.0008494973299093544 loss_recons: 0.8436976075172424\n",
      "loss_prior: 0.0015535712009295821 loss_recons: 1.02874755859375\n",
      "loss_prior: 0.0006301462999545038 loss_recons: 0.8897386789321899\n",
      "loss_prior: 0.0007345527410507202 loss_recons: 0.8192674517631531\n",
      "loss_prior: 0.0007748395437374711 loss_recons: 0.8650230765342712\n",
      "loss_prior: 0.0006540328613482416 loss_recons: 0.8648033142089844\n",
      "loss_prior: 0.0009266108390875161 loss_recons: 0.7572698593139648\n",
      "loss_prior: 0.0007398456218652427 loss_recons: 0.9204559326171875\n",
      "loss_prior: 0.000710627471562475 loss_recons: 0.8857013583183289\n",
      "loss_prior: 0.0006929218652658165 loss_recons: 0.9081907868385315\n",
      "loss_prior: 0.0006249755970202386 loss_recons: 0.9486606121063232\n",
      "loss_prior: 0.0008653551340103149 loss_recons: 0.7522488236427307\n",
      "loss_prior: 0.0005792677402496338 loss_recons: 0.9470155239105225\n",
      "loss_prior: 0.001261806464754045 loss_recons: 0.8960395455360413\n",
      "loss_prior: 0.0008668661466799676 loss_recons: 0.6959851980209351\n",
      "loss_prior: 0.000884884619154036 loss_recons: 0.8483979105949402\n",
      "loss_prior: 0.0008015900966711342 loss_recons: 0.9018312692642212\n",
      "loss_prior: 0.0007483959197998047 loss_recons: 0.9004839658737183\n",
      "loss_prior: 0.0006386876339092851 loss_recons: 0.9449536800384521\n",
      "loss_prior: 0.0007162511465139687 loss_recons: 0.8320443034172058\n",
      "loss_prior: 0.0009279370424337685 loss_recons: 0.9469672441482544\n",
      "loss_prior: 0.0007022112840786576 loss_recons: 0.801964521408081\n",
      "loss_prior: 0.0005676299333572388 loss_recons: 0.8519358038902283\n",
      "loss_prior: 0.0008990138885565102 loss_recons: 0.7511063814163208\n",
      "loss_prior: 0.0006858378765173256 loss_recons: 0.8569098711013794\n",
      "loss_prior: 0.0010131270391866565 loss_recons: 0.8723219633102417\n",
      "loss_prior: 0.0014701783657073975 loss_recons: 0.959703266620636\n",
      "loss_prior: 0.0005016654613427818 loss_recons: 0.7656112909317017\n",
      "loss_prior: 0.001051208353601396 loss_recons: 0.7402135729789734\n",
      "loss_prior: 0.0010991335147991776 loss_recons: 0.8873099684715271\n",
      "loss_prior: 0.0008585811010561883 loss_recons: 0.8869497179985046\n",
      "loss_prior: 0.0008119940757751465 loss_recons: 0.7469067573547363\n",
      "loss_prior: 0.0006863623857498169 loss_recons: 0.7397907376289368\n",
      "loss_prior: 0.0007069051498547196 loss_recons: 0.7812841534614563\n",
      "loss_prior: 0.0020336091984063387 loss_recons: 0.8766725063323975\n",
      "loss_prior: 0.0008057236555032432 loss_recons: 0.8767107725143433\n",
      "loss_prior: 0.0007933765882626176 loss_recons: 1.042348027229309\n",
      "loss_prior: 0.0006556451553478837 loss_recons: 0.7239384651184082\n",
      "loss_prior: 0.0011742919450625777 loss_recons: 1.03573477268219\n",
      "loss_prior: 0.0015829682815819979 loss_recons: 1.3381658792495728\n",
      "loss_prior: 0.0008627325296401978 loss_recons: 0.832790195941925\n",
      "loss_prior: 0.0006805449957028031 loss_recons: 1.0311146974563599\n",
      "loss_prior: 0.0008066773298196495 loss_recons: 0.6417410969734192\n",
      "loss_prior: 0.0007712930673733354 loss_recons: 0.8015211224555969\n",
      "loss_prior: 0.0005743324873037636 loss_recons: 0.9035847783088684\n",
      "loss_prior: 0.0008574128150939941 loss_recons: 0.6884923577308655\n",
      "loss_prior: 0.0009676188346929848 loss_recons: 0.7106317281723022\n",
      "loss_prior: 0.0007786810747347772 loss_recons: 0.8119708895683289\n",
      "loss_prior: 0.001443541026674211 loss_recons: 1.0760513544082642\n",
      "loss_prior: 0.0006369859329424798 loss_recons: 0.8754200339317322\n",
      "loss_prior: 0.000856250524520874 loss_recons: 0.8850996494293213\n",
      "loss_prior: 0.000868186354637146 loss_recons: 0.852800190448761\n",
      "loss_prior: 0.0013785898918285966 loss_recons: 0.8712731599807739\n",
      "loss_prior: 0.0008116126409731805 loss_recons: 0.9421801567077637\n",
      "loss_prior: 0.0007025540107861161 loss_recons: 1.1099380254745483\n",
      "loss_prior: 0.0008316278690472245 loss_recons: 0.8802606463432312\n",
      "loss_prior: 0.000723290431778878 loss_recons: 0.8403864502906799\n",
      "loss_prior: 0.0005953192594461143 loss_recons: 0.9403996467590332\n",
      "loss_prior: 0.0010464162332937121 loss_recons: 0.8638962507247925\n",
      "loss_prior: 0.0007121205562725663 loss_recons: 0.8591042160987854\n",
      "loss_prior: 0.0006175279850140214 loss_recons: 0.9320182800292969\n",
      "loss_prior: 0.0010081649525091052 loss_recons: 0.8186506032943726\n",
      "loss_prior: 0.001126560615375638 loss_recons: 0.7413392663002014\n",
      "loss_prior: 0.0007833719137124717 loss_recons: 0.9402921795845032\n",
      "loss_prior: 0.0008811205625534058 loss_recons: 0.7227147221565247\n",
      "loss_prior: 0.0007342517492361367 loss_recons: 0.8841869235038757\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(args.train_epochs):\n",
    "    for batch in dataloader:\n",
    "        positions = batch['positions']\n",
    "        expressions = batch['expressions']\n",
    "        metadata = batch['metadata']\n",
    "        \n",
    "        # Use the positions, expressions for model training\n",
    "        # The metadata could be used for logging, tracking, or conditioning if needed\n",
    "        # print(positions.shape, expressions.shape)\n",
    "        \n",
    "        x = torch.cat((positions, expressions), dim=2).to(args.device)\n",
    "        \n",
    "        # Reset grad and model state\n",
    "        optimizer.zero_grad()\n",
    "        model.train()\n",
    "        \n",
    "        loss = model.get_loss(x)\n",
    "\n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        orig_grad_norm = clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "    #     break\n",
    "    # break\n",
    "            \n",
    "    # print(\"epoch:\", epoch, \"loss:\", loss.item())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50, 376])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionaries to store metrics for both baselines\n",
    "metrics = {\n",
    "    'Diffusion': {\n",
    "        'mse': [],\n",
    "        'f1': [],\n",
    "        'cosine_sim': [],\n",
    "        'chamfer_dist': [],\n",
    "        'emd': []\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeding all randomness with seed=2024\n",
      "Donor_id: MsBrainAgingSpatialDonor_1\n",
      "Slice_id: 0\n",
      "Donor_id: MsBrainAgingSpatialDonor_2\n",
      "Slice_id: 0\n",
      "Slice_id: 1\n",
      "Donor_id: MsBrainAgingSpatialDonor_3\n",
      "Slice_id: 0\n",
      "Slice_id: 1\n",
      "Donor_id: MsBrainAgingSpatialDonor_4\n",
      "Slice_id: 0\n",
      "Slice_id: 1\n",
      "Slice_id: 2\n",
      "Donor_id: MsBrainAgingSpatialDonor_5\n",
      "Slice_id: 0\n",
      "Slice_id: 1\n",
      "Slice_id: 2\n",
      "Donor_id: MsBrainAgingSpatialDonor_6\n",
      "Slice_id: 0\n",
      "Slice_id: 1\n",
      "Slice_id: 2\n",
      "Donor_id: MsBrainAgingSpatialDonor_7\n",
      "Slice_id: 0\n",
      "Slice_id: 1\n",
      "Slice_id: 2\n",
      "Donor_id: MsBrainAgingSpatialDonor_8\n",
      "Slice_id: 0\n",
      "Slice_id: 1\n",
      "Slice_id: 2\n",
      "Donor_id: MsBrainAgingSpatialDonor_9\n",
      "Slice_id: 0\n",
      "Slice_id: 1\n",
      "Slice_id: 2\n",
      "Donor_id: MsBrainAgingSpatialDonor_10\n",
      "Slice_id: 0\n",
      "Slice_id: 1\n",
      "Slice_id: 2\n",
      "Donor_id: MsBrainAgingSpatialDonor_11\n",
      "Slice_id: 0\n",
      "Slice_id: 1\n",
      "Slice_id: 2\n",
      "Donor_id: MsBrainAgingSpatialDonor_12\n",
      "Slice_id: 0\n",
      "Slice_id: 1\n"
     ]
    }
   ],
   "source": [
    "all_test_items = load_test_data(num_holes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Area 1:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 2:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 3:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 4:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 5:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 6:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 7:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 8:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 9:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 10:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 11:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 12:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 13:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 14:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 15:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 16:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 17:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 18:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 19:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 20:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 21:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 22:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 23:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 24:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 25:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 26:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 27:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 28:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 29:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 30:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 31:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 32:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 33:\n",
      "  Dominant Tissue: cortical layer II/III\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 34:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 35:\n",
      "  Dominant Tissue: cortical layer II/III\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 36:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 37:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 38:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 39:\n",
      "  Dominant Tissue: cortical layer II/III\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 40:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 41:\n",
      "  Dominant Tissue: cortical layer II/III\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 42:\n",
      "  Dominant Tissue: cortical layer II/III\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 43:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 44:\n",
      "  Dominant Tissue: cortical layer II/III\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 45:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 46:\n",
      "  Dominant Tissue: cortical layer II/III\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 47:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 48:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 49:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 50:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 51:\n",
      "  Dominant Tissue: cortical layer II/III\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 52:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 53:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 54:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 55:\n",
      "  Dominant Tissue: cortical layer II/III\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 56:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 57:\n",
      "  Dominant Tissue: cortical layer II/III\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 58:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 59:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 60:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 61:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 62:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 63:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 64:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 65:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 66:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 67:\n",
      "  Dominant Tissue: cortical layer II/III\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 68:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 69:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 70:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 71:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 72:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 73:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 74:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 75:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 76:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 77:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 78:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 79:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 80:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 81:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 82:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 83:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 84:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 85:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 86:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 87:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 88:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 89:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 90:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 91:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 92:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 93:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 94:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 95:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 96:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 97:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 98:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 99:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 100:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 101:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 102:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 103:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 104:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 105:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 106:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 107:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 108:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 109:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 110:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 111:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 112:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 113:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 114:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 115:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 116:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 117:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 118:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 119:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 120:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 121:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 122:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 123:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 124:\n",
      "  Dominant Tissue: cortical layer II/III\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 125:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 126:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 127:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 128:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 129:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 130:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 131:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 132:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 133:\n",
      "  Dominant Tissue: cortical layer II/III\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 134:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 135:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 136:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 137:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 138:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 139:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 140:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 141:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 142:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 143:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 144:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 145:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 146:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 147:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 148:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 149:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 150:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 151:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 152:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 153:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 154:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 155:\n",
      "  Dominant Tissue: pia mater\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 156:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 157:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 158:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 159:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 160:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 161:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 162:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 163:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 164:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 165:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 166:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 167:\n",
      "  Dominant Tissue: cortical layer II/III\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 168:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 169:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 170:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 171:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 172:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 173:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 174:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 175:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 176:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 177:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 178:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 179:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 180:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 181:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 182:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 183:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 184:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 185:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 186:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 187:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 188:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 189:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 190:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 191:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 192:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 193:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 194:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 195:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 196:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 197:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 198:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 199:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 200:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 201:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 202:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 203:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 204:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 205:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 206:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 207:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 208:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 209:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 210:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 211:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 212:\n",
      "  Dominant Tissue: cortical layer II/III\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 213:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 214:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 215:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 216:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 217:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 218:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 219:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 220:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 221:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 222:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 223:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 224:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 225:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 226:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 227:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 228:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 229:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 230:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 231:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 232:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 233:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 234:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 235:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 236:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 237:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 238:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 239:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 240:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 241:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 242:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 243:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 244:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 245:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 246:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 247:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 248:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 249:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 250:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 251:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 252:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 253:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 254:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 255:\n",
      "  Dominant Tissue: cortical layer II/III\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 256:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 257:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 258:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 259:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 260:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 261:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 262:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 263:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 264:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 265:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 266:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 267:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 268:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 269:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 270:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 271:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 272:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 273:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 274:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 275:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 276:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 277:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 278:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 279:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 280:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 281:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 282:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 283:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 284:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 285:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 286:\n",
      "  Dominant Tissue: corpus callosum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 287:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 288:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 289:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 290:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 291:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 292:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 293:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 294:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 295:\n",
      "  Dominant Tissue: cortical layer II/III\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 296:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 297:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 298:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 299:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 300:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 301:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 302:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 303:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 304:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 305:\n",
      "  Dominant Tissue: cortical layer V\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 306:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 307:\n",
      "  Dominant Tissue: cortical layer II/III\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 308:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 309:\n",
      "  Dominant Tissue: cortical layer VI\n",
      "  Number of cells in ground truth: 50\n",
      "Test Area 310:\n",
      "  Dominant Tissue: striatum\n",
      "  Number of cells in ground truth: 50\n"
     ]
    }
   ],
   "source": [
    "for i, test_item in enumerate(all_test_items):\n",
    "    print(f\"Test Area {i+1}:\")\n",
    "    print(f\"  Dominant Tissue: {test_item.test_area.dominant_tissue}\")\n",
    "    print(f\"  Number of cells in ground truth: {len(test_item.ground_truth.hole_cells)}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        z = torch.randn([1, args.latent_dim]).to(args.device)\n",
    "        x = model.sample(z, 50)\n",
    "\n",
    "    true_coords = test_item.ground_truth.hole_cells[['center_x', 'center_y']].values\n",
    "    true_gene_expressions = test_item.ground_truth.gene_expression\n",
    "\n",
    "    pred_coords, pred_gene_expressions = x[0,:,:2].cpu().numpy(), x[0,:,2:].cpu().numpy()\n",
    "\n",
    "    mse_r, f1_r, cosine_sim_r = Evaluator.evaluate_expression(true_coords, true_gene_expressions, pred_coords, pred_gene_expressions)\n",
    "    chamfer_dist_r = Evaluator.chamfer_distance(true_coords, pred_coords)\n",
    "    emd_r = Evaluator.calculate_emd(true_coords, pred_coords)\n",
    "    \n",
    "    # Collect results for RandomRegionBaseline\n",
    "    metrics['Diffusion']['mse'].append(mse_r)\n",
    "    metrics['Diffusion']['f1'].append(f1_r)\n",
    "    metrics['Diffusion']['cosine_sim'].append(cosine_sim_r)\n",
    "    metrics['Diffusion']['chamfer_dist'].append(chamfer_dist_r)\n",
    "    metrics['Diffusion']['emd'].append(emd_r)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Diffusion:\n",
      "  Mse: Mean = 1.4475, Std = 0.3142\n",
      "  F1: Mean = 0.5508, Std = 0.0335\n",
      "  Cosine_sim: Mean = 0.0066, Std = 0.0317\n",
      "  Chamfer_dist: Mean = 9278.6375, Std = 3955.5474\n",
      "  Emd: Mean = 4691.1569, Std = 1977.6617\n"
     ]
    }
   ],
   "source": [
    "for method in metrics:\n",
    "    print(f\"Results for {method}:\")\n",
    "    for metric in metrics[method]:\n",
    "        mean_value = np.mean(metrics[method][metric])\n",
    "        std_value = np.std(metrics[method][metric])\n",
    "        print(f\"  {metric.capitalize()}: Mean = {mean_value:.4f}, Std = {std_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
